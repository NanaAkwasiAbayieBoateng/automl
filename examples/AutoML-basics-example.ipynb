{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onepanel AutoML 0.1.5\n",
    "\n",
    "Onepanel AutoML is a framework that allows automated machine learning pipelines to be built easily and declaratively, running them locally (current implementation) or on a cluster (TBD).\n",
    "\n",
    "The framework can be easily extened with new features. Currently AutoML is integrated with popular open-source machine learning libraries Scikit-learn and Hyperopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# AutoML uses Python's logging module\n",
    "import logging\n",
    "\n",
    "# Various sklearn models and metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# AutoML Classes\n",
    "from automl.pipeline import LocalExecutor, Pipeline, PipelineStep, PipelineData\n",
    "from automl.data.dataset import Dataset\n",
    "from automl.model import ModelSpace, CV, Validate, ChooseBest\n",
    "from automl.hyperparam.templates import (random_forest_hp_space, \n",
    "                                         knn_hp_space, svc_kernel_hp_space, \n",
    "                                         grad_boosting_hp_space, \n",
    "                                         xgboost_hp_space)\n",
    "from automl.feature.generators import FormulaFeatureGenerator\n",
    "from automl.feature.selector import FeatureSelector\n",
    "from automl.hyperparam.optimization import Hyperopt\n",
    "from automl.combinators import RandomChoice\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core concepts\n",
    "AutoML follows code-is-data and data-is-code philosophy. You define automated machine learning pipelines as data structures that can be executed later.\n",
    "\n",
    "Key concepts in AutoML are:\n",
    "\n",
    "* `Pipeline` - a machine learning pipeline. It executes various steps inside the pipeline passing each step output as an input to the next step\n",
    "* `PipelineStep` - all `Pipeline`s consist of steps. AutoML provide lots of several different steps out of the box\n",
    "* `Executor` - executes a pipeline. Currently AutoML provides `LocalExecutor` which runs pipeline locally. Future versions will have `DistributedExecutor` built-in\n",
    "\n",
    "AutoML can easily be extended by implementing `PipelineStep`s. \n",
    "\n",
    "Next, we will use various built-in `PipelineStep`s to create an automated classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.5\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "LocalExecutor - INFO - Dataset columns: ['base_feature_0', 'base_feature_1', 'base_feature_2', 'base_feature_3', 'base_feature_4', 'base_feature_5', 'base_feature_6', 'base_feature_7', 'base_feature_8', 'base_feature_9', 'base_feature_10', 'base_feature_11', 'base_feature_12', 'base_feature_13', 'base_feature_14', 'base_feature_15', 'base_feature_16', 'base_feature_17', 'base_feature_18', 'base_feature_19', 'base_feature_20', 'base_feature_21', 'base_feature_22', 'base_feature_23', 'base_feature_24', 'base_feature_25', 'base_feature_26', 'base_feature_27', 'base_feature_28', 'base_feature_29', 'base_feature_30', 'base_feature_31', 'base_feature_32', 'base_feature_33', 'base_feature_34', 'base_feature_35', 'base_feature_36', 'base_feature_37', 'base_feature_38', 'base_feature_39']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 40, new feature number - 41\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x10ca16b70>, 'max_features': <hyperopt.pyll.base.Apply object at 0x10ca16f28>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x10ca17278>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x10ca17630>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x10ca17780>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x10ca17898>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004116 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║\n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║\n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.004947 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.087515\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003472 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.058344\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003409 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.058344\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004041 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.058344\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'n_neighbors': <hyperopt.pyll.base.Apply object at 0x10ca17a90>, 'weights': <hyperopt.pyll.base.Apply object at 0x10ca17ba8>, 'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'p': 2, 'metric_params': None, 'n_jobs': 1}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001300 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001186 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.113831\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001250 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.087515\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001292 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.087515\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001115 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.087515\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x10ca17da0>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x10ca17f28>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x10ca26160>, 'gamma': <hyperopt.pyll.base.Apply object at 0x10ca262e8>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x10ca264a8>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x10ca265f8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x10ca26748>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x10ca26898>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x10ca26a20>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x10ca26ba8>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x10ca26c50>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005414 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004128 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.069971\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004011 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.069971\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003856 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.069971\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004393 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.069971\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:22<00:14,  7.36s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=27, n_jobs=1,\n",
      "            oob_score=False, random_state=3, verbose=False,\n",
      "            warm_start=False) - 0.9416564667482661\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.5779843082106891,\n",
      "       colsample_bytree=0.62450767919489, gamma=0.00041345464641842975,\n",
      "       learning_rate=9.234601037686934e-05, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=3, missing=None, n_estimators=1600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.0019288555437411566, reg_lambda=2.87296852187409,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.6760834919981945) - 0.9300285597715219\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=29, p=2,\n",
      "           weights='distance') - 0.912484700122399\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - INFO - Removing 10 features for model RandomForestClassifier\n",
      "100%|██████████| 5/5 [00:22<00:00,  4.42s/it]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #2\n",
      "LocalExecutor - INFO - Dataset columns: ['base_feature_2', 'base_feature_4', 'base_feature_5', 'base_feature_8', 'base_feature_9', 'base_feature_13', 'base_feature_15', 'base_feature_26', 'base_feature_30', 'base_feature_36']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 10, new feature number - 11\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x10ca16b70>, 'max_features': <hyperopt.pyll.base.Apply object at 0x10ca16f28>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x10ca17278>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x10ca17630>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x10ca17780>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x10ca17898>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003694 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003357 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.122399\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003527 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.122399\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003568 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.110771\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.036274 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.099143\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'n_neighbors': <hyperopt.pyll.base.Apply object at 0x10ca17a90>, 'weights': <hyperopt.pyll.base.Apply object at 0x10ca17ba8>, 'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'p': 2, 'metric_params': None, 'n_jobs': 1}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001155 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001094 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.110771\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001721 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.110771\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001152 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.069971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.001126 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.069971\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x10ca17da0>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x10ca17f28>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x10ca26160>, 'gamma': <hyperopt.pyll.base.Apply object at 0x10ca262e8>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x10ca264a8>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x10ca265f8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x10ca26748>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x10ca26898>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x10ca26a20>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x10ca26ba8>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x10ca26c50>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003976 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003831 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.069971\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003749 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.069971\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003796 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.069971\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003669 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.069971\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:16<00:11,  5.63s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=21, p=2,\n",
      "           weights='uniform') - 0.9416564667482661\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.19677415443465818,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=31,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=59, n_jobs=1, oob_score=False, random_state=3,\n",
      "            verbose=False, warm_start=False) - 0.9300285597715219\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.8010888662962187,\n",
      "       colsample_bytree=0.5564344133375643, gamma=0.0033681789822068054,\n",
      "       learning_rate=0.0003283667856103649, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=10, missing=None, n_estimators=5000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.014563236557066978, reg_lambda=1.9381863739352605,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.9846399057400854) - 0.9300285597715219\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - WARNING - Model KNeighborsClassifier is not supported by FeatureSelector\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=21, p=2,\n",
      "           weights='uniform') 0.9416564667482661\n",
      "(1000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Let's create a dataset first\n",
    "x, y = make_classification(\n",
    "      n_samples=1000,\n",
    "      n_features=40,\n",
    "      n_informative=2,\n",
    "      n_redundant=10,\n",
    "      flip_y=0.05)\n",
    "\n",
    "# We will use AutoML Dataset class to wrap our data \n",
    "# into structure that can be understood by AutoML\n",
    "data = Dataset(x, y)\n",
    "\n",
    "# Next, we define our ModelSpace. ModelSpace is initialized by a list of tuples.\n",
    "# First element of each tuple should be an sklearn-like estimator with fit method\n",
    "# The second one is model parameter dictionary. Here we do not define parameters \n",
    "# explicitly, but use hyperparameter templates from AutoML. Those templates can be\n",
    "# used later by Hyperopt step to find best model parameters automatically\n",
    "model_list = [\n",
    "      (RandomForestClassifier, random_forest_hp_space()),\n",
    "      (KNeighborsClassifier, knn_hp_space(lambda key: key)),\n",
    "      (XGBClassifier, xgboost_hp_space())\n",
    "  ]\n",
    "\n",
    "\n",
    "# Create executor, initialize it with our classification dataset \n",
    "# and set total number of epochs to 2 (the pipeline will be run two times in a row).\n",
    "# We can load any pipeline into executor using << operator like below:\n",
    "context, pipeline_data = LocalExecutor(data, epochs=2) << \\\n",
    "    (Pipeline() # Here we define the pipeline. Steps can be added to pipeline using >> operator\n",
    "     # First we define our ModelSpace. We wrap it with PipelineStep class \n",
    "     # and set initializer=True so that ModelSpace step will be run only at the first epoch\n",
    "     >> PipelineStep('model space', ModelSpace(model_list), initializer=True)\n",
    "     # But we are not obliged to wrap all steps with PipelineStep.\n",
    "     # This will be done automatically if we do not need to set any special parameters \n",
    "     # We use FormulaFeatureGenerator to create arithmetic combinations of features from the dataset\n",
    "     >> FormulaFeatureGenerator(['+', '-', '*']) \n",
    "     # Next we use Hyperopt to find the best combination of hyperparameters for each model\n",
    "     # We use test set validation with ROC AUC metric as a score function.\n",
    "     # CV could be used instead of Validate to perform cross-validation\n",
    "     >> Hyperopt(Validate(test_size=0.1, metrics=roc_auc_score), max_evals=5) \n",
    "     # Then we choose the best performing model we found\n",
    "     >> ChooseBest(1)\n",
    "     # And select 10 best features\n",
    "     >> FeatureSelector(10))\n",
    "\n",
    "for result in pipeline_data.return_val:\n",
    "    print(result.model, result.score)\n",
    "print(pipeline_data.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending AutoML\n",
    "\n",
    "First, let's look at how `PipelineStep`s can be created by creating a simple hello world pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.5\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'hello_step'\n",
      "100%|██████████| 1/1 [00:00<00:00, 301.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║\n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║\n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n",
      "Hello!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<automl.pipeline.PipelineContext at 0x1076827b8>, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a simple pipeline\n",
    "pipeline = Pipeline() >> PipelineStep('hello_step', lambda inp, context: print(\"Hello!\"))\n",
    "\n",
    "# And execute it locally\n",
    "LocalExecutor() << pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see steps can be added to a pipeline using `>>` operator. A pipeline may contain any number of steps. Any `PipelineStep` is constructed by passing a step name and a `callable` which will be executed when `Pipeline` is run by an `Executor`. It's important to mention that all `Pipeline`s are lazy and all steps inside will be executed only when `Pipeline` is loaded into `Executor.`\n",
    "\n",
    "`PipelineStep` syntax is pretty verbose, but it can be simplified. You can pass any `callable` to a pipeline and it will be wrapped into `PipelineStep` automatically. Step function should have two arguments: `input` and `context`. `input` must be loaded through executor parameters, `context` contains global variables, available for each step. If `PipelineStep` returns any value, it should wrap it into `PipelineData` class. `input` passed to an `Executor` is wrapped to `PipelineData` automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.5\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'RandomChoice'\n",
      "100%|██████████| 1/1 [00:00<00:00, 996.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║\n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║\n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<automl.pipeline.PipelineContext at 0x10ca12e10>, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create two steps that add 1 and 2 to input data\n",
    "plus_one = PipelineStep('plus_one', lambda inp, context: inp.dataset + 1)\n",
    "plus_two = PipelineStep('plus_two', lambda inp, context: inp.dataset + 2)\n",
    "\n",
    "LocalExecutor(0) << \\\n",
    "    (Pipeline()\n",
    "     # We use RandomChoice combinator to choose randomly between two steps while executing the pipeline\n",
    "     >> RandomChoice([plus_one, plus_two]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to create complex callables for `PipelineStep`s as classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.5\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'ComplexStep'\n",
      "100%|██████████| 1/1 [00:00<00:00, 701.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ComplexStep\n",
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║\n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║\n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n",
      "<automl.pipeline.PipelineData object at 0x10ca12d30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<automl.pipeline.PipelineContext at 0x10ca126a0>,\n",
       " <automl.pipeline.PipelineData at 0x10ca12d30>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ComplexStep:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing ComplexStep\")\n",
    "        \n",
    "    def __call__(self, inp, context):\n",
    "        print(inp)\n",
    "        return inp\n",
    "    \n",
    "LocalExecutor() << (Pipeline() >> ComplexStep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
