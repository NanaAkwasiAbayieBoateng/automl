{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onepanel AutoML 0.1.5 - Kaggle Dataset Example\n",
    "\n",
    "Here we use AutoML to solve a classification task on a classic [Titanic](https://www.kaggle.com/c/titanic) dataset from Kaggle. First, let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived Pclass  \\\n",
       "0            1         0      3   \n",
       "1            2         1      1   \n",
       "2            3         1      3   \n",
       "3            4         1      1   \n",
       "4            5         0      3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/train.csv', parse_dates=[2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "# AutoML uses Python's logging module\n",
    "import logging\n",
    "\n",
    "# Various sklearn models and metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, make_scorer\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# AutoML Clasees\n",
    "from automl.pipeline import LocalExecutor, Pipeline, PipelineStep, PipelineData\n",
    "from automl.data.dataset import Dataset\n",
    "from automl.model import ModelSpace, CV, Validate, ChooseBest\n",
    "from automl.hyperparam.templates import (random_forest_hp_space, \n",
    "                                         knn_hp_space, svc_kernel_hp_space, \n",
    "                                         grad_boosting_hp_space, \n",
    "                                         xgboost_hp_space)\n",
    "from automl.feature.generators import FormulaFeatureGenerator, PolynomialGenerator\n",
    "from automl.feature.selector import FeatureSelector\n",
    "from automl.hyperparam.optimization import Hyperopt\n",
    "from automl.combinators import RandomChoice\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how automated our process is, data still may need some preprocessing. Also, doing good old feature engenering can help by a lot. We skip exploratory data analysis and feature engeneering stages for brevity. If you are interested, we suggest looking up some examples at contest's [kernels](https://www.kaggle.com/c/titanic/kernels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'IsAlone']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess data and create AutoML Dataset\"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    result = df.copy()\n",
    "    \n",
    "    # drop columns we won't be using\n",
    "    result.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "    \n",
    "    # transform Sex column into numeric categories\n",
    "    result['Sex'] = encoder.fit_transform(result['Sex'])\n",
    "    \n",
    "    # do the same with Embarked column\n",
    "    result['Embarked'] = encoder.fit_transform(result['Embarked'].astype(str))\n",
    "    \n",
    "    # Replace missing Ages with median value and \"pack\"\n",
    "    # Age into 10 equal-sized bins. For example, all \n",
    "    # ages from 0-10 will be packed into bin 0.\n",
    "    result['Age'].fillna(result['Age'].median(), inplace=True)\n",
    "    result['Age'] = pd.cut(result['Age'], 10, labels=range(0,10)).astype(int)\n",
    "    \n",
    "    # Pack Fare into 10 bins\n",
    "    result['Fare'] = pd.cut(result['Fare'], 10, labels=range(0,10)).astype(int)\n",
    "    \n",
    "    # transform Pclass type to int\n",
    "    result['Pclass'] = result['Pclass'].astype(int)\n",
    "    \n",
    "    # add some useful predictive features that may came \n",
    "    # up to mind during data analysis\n",
    "    result['FamilySize'] = result['SibSp'] + result['Parch'] + 1\n",
    "    result['IsAlone'] = 0\n",
    "    result.loc[result['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "    return Dataset(result.drop(['Survived'], axis=1),\n",
    "                   result['Survived'])\n",
    "\n",
    "dataset = preprocess_data(data)\n",
    "print(f\"Features: {dataset.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit simple XGBoost model with default parameters and see how it scores on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81144781144781142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rf = XGBClassifier()\n",
    "np.mean(cross_val_score(rf, dataset.data, dataset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, 81% accuracy with the defaults. Let's go on to AutoML Pipelines and see if we can improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.5\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'IsAlone']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "LocalExecutor - INFO - Running step 'SklearnFeatureGenerator'\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x1147959e8>, 'max_features': <hyperopt.pyll.base.Apply object at 0x114795da0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x1147c40b8>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x1147c41d0>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x1147c43c8>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x1147c44e0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005381 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║\n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║\n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.004156 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004237 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004591 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004515 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004059 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004067 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004074 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.176207\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004502 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004504 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003826 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003955 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004698 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004774 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004244 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.176207\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004310 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.173962\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004306 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.173962\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005139 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.173962\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004640 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.173962\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004504 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.173962\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'n_neighbors': <hyperopt.pyll.base.Apply object at 0x1147c46d8>, 'weights': <hyperopt.pyll.base.Apply object at 0x1147c47f0>, 'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'p': 2, 'metric_params': None, 'n_jobs': 1}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001450 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002347 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.236813\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002332 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.236813\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002816 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.236813\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002350 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.236813\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002449 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.236813\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003161 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002203 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002474 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002181 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002264 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002533 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002771 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002194 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002077 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002462 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002074 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002318 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003065 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.232323\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002457 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.231201\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x1147c49e8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x1147c4b70>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x1147c4d68>, 'gamma': <hyperopt.pyll.base.Apply object at 0x1147c4ef0>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x1147cf0f0>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x1147cf240>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x1147cf390>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x1147cf4e0>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x1147cf668>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x1147cf7f0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x1147cf898>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005218 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004288 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.199776\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004609 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.009228 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006300 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.199776\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.005452 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005175 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004998 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004948 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007446 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005935 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005151 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005070 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004391 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004682 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004672 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004335 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005022 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004641 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004416 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [02:20<01:33, 46.93s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=0.257934964718071,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=53, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.8260381593714926\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.9743802836847419,\n",
      "       colsample_bytree=0.6891635364105053, gamma=4.96517143701691,\n",
      "       learning_rate=3.399844395381221e-05, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=7, missing=None, n_estimators=5600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.40293690325764736, reg_lambda=1.1406984782496297,\n",
      "       scale_pos_weight=1, seed=2, silent=True,\n",
      "       subsample=0.6631341411654122) - 0.8215488215488215\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='distance') - 0.7687991021324354\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - INFO - Removing 20 features for model RandomForestClassifier\n",
      "100%|██████████| 5/5 [02:20<00:00, 28.16s/it]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #2\n",
      "LocalExecutor - INFO - Dataset columns: ['Sex', 'Age', 'SibSp', 'Parch', 'IsAlone']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'SklearnFeatureGenerator'\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x1147959e8>, 'max_features': <hyperopt.pyll.base.Apply object at 0x114795da0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x1147c40b8>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x1147c41d0>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x1147c43c8>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x1147c44e0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004106 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004281 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003840 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.204265\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003764 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.204265\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005966 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004225 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004291 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004259 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004381 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.175084\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003787 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004256 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.175084\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003750 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003971 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.175084\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003685 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003576 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.175084\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003932 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.175084\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003899 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004088 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004361 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004203 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.175084\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'n_neighbors': <hyperopt.pyll.base.Apply object at 0x1147c46d8>, 'weights': <hyperopt.pyll.base.Apply object at 0x1147c47f0>, 'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'p': 2, 'metric_params': None, 'n_jobs': 1}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001309 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002779 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.222222\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002887 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002292 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003295 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002993 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002180 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002717 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002261 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002906 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002374 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002109 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003315 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003213 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002279 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002086 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001970 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002378 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002269 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.207632\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002749 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.207632\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x1147c49e8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x1147c4b70>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x1147c4d68>, 'gamma': <hyperopt.pyll.base.Apply object at 0x1147c4ef0>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x1147cf0f0>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x1147cf240>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x1147cf390>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x1147cf4e0>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x1147cf668>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x1147cf7f0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x1147cf898>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006117 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005139 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.213244\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004922 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.213244\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004550 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.213244\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004762 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.213244\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004577 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.204265\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004660 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.204265\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004599 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.204265\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005671 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.204265\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004783 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.203143\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004695 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.203143\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005785 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.203143\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006638 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004717 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004910 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005249 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005127 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004649 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004618 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004778 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [09:01<06:00, 180.36s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=0.1300828845731834,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=319, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=False, warm_start=False) - 0.8260381593714928\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7516621347923008,\n",
      "       colsample_bytree=0.8920819384240011, gamma=2.571556575164393,\n",
      "       learning_rate=0.053894974632613446, max_delta_step=0, max_depth=1,\n",
      "       min_child_weight=5, missing=None, n_estimators=4600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.03825788473425302, reg_lambda=1.1645765077112509,\n",
      "       scale_pos_weight=1, seed=0, silent=True,\n",
      "       subsample=0.7687782949167214) - 0.8069584736251404\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=14, p=2,\n",
      "           weights='uniform') - 0.7923681257014591\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - INFO - Removing 20 features for model RandomForestClassifier\n",
      "100%|██████████| 5/5 [09:01<00:00, 108.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=0.1300828845731834,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=319, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=False, warm_start=False) 0.8260381593714928\n",
      "(891, 20)\n"
     ]
    }
   ],
   "source": [
    "# Next, we define our ModelSpace. ModelSpace is initialized by a list of tuples.\n",
    "# First element of each tuple should be an sklearn-like estimator with fit method\n",
    "# The second one is model parameter dictionary. Here we do not define parameters \n",
    "# explicitly, but use hyperparameter templates from AutoML. Those templates can be\n",
    "# used later by Hyperopt step to find best model parameters automatically\n",
    "model_list = [\n",
    "      (RandomForestClassifier, random_forest_hp_space()),\n",
    "      (KNeighborsClassifier, knn_hp_space(lambda key: key)),\n",
    "      (XGBClassifier, xgboost_hp_space())\n",
    "  ]\n",
    "\n",
    "\n",
    "# Create executor, initialize it with our classification dataset \n",
    "# and set total number of epochs to 2 (the pipeline will be run two times in a row).\n",
    "# We can load any pipeline into executor using << operator like below:\n",
    "context, pipeline_data = LocalExecutor(dataset, epochs=2) << \\\n",
    "    (Pipeline() # Here we define the pipeline. Steps can be added to pipeline using >> operator\n",
    "     # First we define our ModelSpace. We wrap it with PipelineStep class \n",
    "     # and set initializer=True so that ModelSpace step will be run only at the first epoch\n",
    "     >> PipelineStep('model space', ModelSpace(model_list), initializer=True)\n",
    "     # But we are not obliged to wrap all steps with PipelineStep.\n",
    "     # This will be done automatically if we do not need to set any special parameters \n",
    "     # We use PolynomialGenerator to create polynomial combinations of the features from the dataset\n",
    "     >> PolynomialGenerator()\n",
    "     # Next we use Hyperopt to find the best combination of hyperparameters for each model\n",
    "     # We use test set validation with accuracy metric as a score function.\n",
    "     # CV could be used instead of Validate to perform cross-validation\n",
    "     >> Hyperopt(CV(scoring=make_scorer(accuracy_score)), max_evals=20)\n",
    "     # Then we choose the best performing model we found\n",
    "     >> ChooseBest(1)\n",
    "     # And select 10 best features\n",
    "     >> FeatureSelector(20))\n",
    "\n",
    "for result in pipeline_data.return_val:\n",
    "    print(result.model, result.score)\n",
    "print(pipeline_data.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have reached better accuracy compared to default XGBoost plain dataset. However, first pipeline we launched had a good job of generating various features for our dataset, but it was not really created for searching the best model. Now let's create a pipeline which will search for the best model on a fixed dataset.\n",
    "\n",
    "Please note that increasing `max_evals` parameter for `Hyperopt` can lead to finding better model parameters, but we use modest values here for demonstation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.5\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "LocalExecutor - INFO - Dataset columns: ['Age']\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x1147959e8>, 'max_features': <hyperopt.pyll.base.Apply object at 0x114795da0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x1147c40b8>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x1147c41d0>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x1147c43c8>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x1147c44e0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004771 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║\n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║\n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.004314 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.203143\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003817 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.203143\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004985 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.190797\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003829 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.190797\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005366 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.190797\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004957 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.190797\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003651 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.190797\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005338 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.190797\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003888 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.190797\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004056 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.187430\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003942 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.187430\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004109 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.187430\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006517 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.187430\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003684 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.187430\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005031 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.187430\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004413 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.187430\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004199 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.187430\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005071 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003774 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004175 seconds\n",
      "hyperopt.tpe - INFO - TPE using 20/20 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004550 seconds\n",
      "hyperopt.tpe - INFO - TPE using 21/21 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005653 seconds\n",
      "hyperopt.tpe - INFO - TPE using 22/22 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004807 seconds\n",
      "hyperopt.tpe - INFO - TPE using 23/23 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004101 seconds\n",
      "hyperopt.tpe - INFO - TPE using 24/24 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004036 seconds\n",
      "hyperopt.tpe - INFO - TPE using 25/25 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006241 seconds\n",
      "hyperopt.tpe - INFO - TPE using 26/26 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005249 seconds\n",
      "hyperopt.tpe - INFO - TPE using 27/27 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004993 seconds\n",
      "hyperopt.tpe - INFO - TPE using 28/28 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003949 seconds\n",
      "hyperopt.tpe - INFO - TPE using 29/29 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004139 seconds\n",
      "hyperopt.tpe - INFO - TPE using 30/30 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003951 seconds\n",
      "hyperopt.tpe - INFO - TPE using 31/31 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003746 seconds\n",
      "hyperopt.tpe - INFO - TPE using 32/32 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004077 seconds\n",
      "hyperopt.tpe - INFO - TPE using 33/33 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004322 seconds\n",
      "hyperopt.tpe - INFO - TPE using 34/34 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003960 seconds\n",
      "hyperopt.tpe - INFO - TPE using 35/35 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004556 seconds\n",
      "hyperopt.tpe - INFO - TPE using 36/36 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004150 seconds\n",
      "hyperopt.tpe - INFO - TPE using 37/37 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003814 seconds\n",
      "hyperopt.tpe - INFO - TPE using 38/38 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003644 seconds\n",
      "hyperopt.tpe - INFO - TPE using 39/39 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003706 seconds\n",
      "hyperopt.tpe - INFO - TPE using 40/40 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004249 seconds\n",
      "hyperopt.tpe - INFO - TPE using 41/41 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003552 seconds\n",
      "hyperopt.tpe - INFO - TPE using 42/42 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004532 seconds\n",
      "hyperopt.tpe - INFO - TPE using 43/43 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004023 seconds\n",
      "hyperopt.tpe - INFO - TPE using 44/44 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003615 seconds\n",
      "hyperopt.tpe - INFO - TPE using 45/45 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003836 seconds\n",
      "hyperopt.tpe - INFO - TPE using 46/46 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004306 seconds\n",
      "hyperopt.tpe - INFO - TPE using 47/47 trials with best loss 0.178451\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004164 seconds\n",
      "hyperopt.tpe - INFO - TPE using 48/48 trials with best loss 0.178451\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003862 seconds\n",
      "hyperopt.tpe - INFO - TPE using 49/49 trials with best loss 0.178451\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'n_neighbors': <hyperopt.pyll.base.Apply object at 0x1147c46d8>, 'weights': <hyperopt.pyll.base.Apply object at 0x1147c47f0>, 'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'p': 2, 'metric_params': None, 'n_jobs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001306 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002850 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.314254\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002563 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002489 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003026 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002179 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002440 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002684 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002603 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003458 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002857 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002493 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003786 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002474 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.196409\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002882 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.195286\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002559 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.195286\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002565 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.195286\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003270 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.195286\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003302 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.185185\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002534 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.185185\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002553 seconds\n",
      "hyperopt.tpe - INFO - TPE using 20/20 trials with best loss 0.185185\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003152 seconds\n",
      "hyperopt.tpe - INFO - TPE using 21/21 trials with best loss 0.185185\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003082 seconds\n",
      "hyperopt.tpe - INFO - TPE using 22/22 trials with best loss 0.185185\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003146 seconds\n",
      "hyperopt.tpe - INFO - TPE using 23/23 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002849 seconds\n",
      "hyperopt.tpe - INFO - TPE using 24/24 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002409 seconds\n",
      "hyperopt.tpe - INFO - TPE using 25/25 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002452 seconds\n",
      "hyperopt.tpe - INFO - TPE using 26/26 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003579 seconds\n",
      "hyperopt.tpe - INFO - TPE using 27/27 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003266 seconds\n",
      "hyperopt.tpe - INFO - TPE using 28/28 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002689 seconds\n",
      "hyperopt.tpe - INFO - TPE using 29/29 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002468 seconds\n",
      "hyperopt.tpe - INFO - TPE using 30/30 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002566 seconds\n",
      "hyperopt.tpe - INFO - TPE using 31/31 trials with best loss 0.182941\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002905 seconds\n",
      "hyperopt.tpe - INFO - TPE using 32/32 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002496 seconds\n",
      "hyperopt.tpe - INFO - TPE using 33/33 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002170 seconds\n",
      "hyperopt.tpe - INFO - TPE using 34/34 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002492 seconds\n",
      "hyperopt.tpe - INFO - TPE using 35/35 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002224 seconds\n",
      "hyperopt.tpe - INFO - TPE using 36/36 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002590 seconds\n",
      "hyperopt.tpe - INFO - TPE using 37/37 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003306 seconds\n",
      "hyperopt.tpe - INFO - TPE using 38/38 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002204 seconds\n",
      "hyperopt.tpe - INFO - TPE using 39/39 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002424 seconds\n",
      "hyperopt.tpe - INFO - TPE using 40/40 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002500 seconds\n",
      "hyperopt.tpe - INFO - TPE using 41/41 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003255 seconds\n",
      "hyperopt.tpe - INFO - TPE using 42/42 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003532 seconds\n",
      "hyperopt.tpe - INFO - TPE using 43/43 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002503 seconds\n",
      "hyperopt.tpe - INFO - TPE using 44/44 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002421 seconds\n",
      "hyperopt.tpe - INFO - TPE using 45/45 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002814 seconds\n",
      "hyperopt.tpe - INFO - TPE using 46/46 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002510 seconds\n",
      "hyperopt.tpe - INFO - TPE using 47/47 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002323 seconds\n",
      "hyperopt.tpe - INFO - TPE using 48/48 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.002819 seconds\n",
      "hyperopt.tpe - INFO - TPE using 49/49 trials with best loss 0.182941\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x1147c49e8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x1147c4b70>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x1147c4d68>, 'gamma': <hyperopt.pyll.base.Apply object at 0x1147c4ef0>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x1147cf0f0>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x1147cf240>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x1147cf390>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x1147cf4e0>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x1147cf668>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x1147cf7f0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x1147cf898>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004880 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005329 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.383838\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004977 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.215488\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004597 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.205387\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006257 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.194164\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004806 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.194164\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004320 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004426 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006391 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004402 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004800 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004697 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004829 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006163 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005458 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005076 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004671 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.193042\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004974 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.193042\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004828 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004678 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004945 seconds\n",
      "hyperopt.tpe - INFO - TPE using 20/20 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004933 seconds\n",
      "hyperopt.tpe - INFO - TPE using 21/21 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004610 seconds\n",
      "hyperopt.tpe - INFO - TPE using 22/22 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004942 seconds\n",
      "hyperopt.tpe - INFO - TPE using 23/23 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004850 seconds\n",
      "hyperopt.tpe - INFO - TPE using 24/24 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004823 seconds\n",
      "hyperopt.tpe - INFO - TPE using 25/25 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006524 seconds\n",
      "hyperopt.tpe - INFO - TPE using 26/26 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004864 seconds\n",
      "hyperopt.tpe - INFO - TPE using 27/27 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004745 seconds\n",
      "hyperopt.tpe - INFO - TPE using 28/28 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004784 seconds\n",
      "hyperopt.tpe - INFO - TPE using 29/29 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005406 seconds\n",
      "hyperopt.tpe - INFO - TPE using 30/30 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004868 seconds\n",
      "hyperopt.tpe - INFO - TPE using 31/31 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004799 seconds\n",
      "hyperopt.tpe - INFO - TPE using 32/32 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004597 seconds\n",
      "hyperopt.tpe - INFO - TPE using 33/33 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004644 seconds\n",
      "hyperopt.tpe - INFO - TPE using 34/34 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004738 seconds\n",
      "hyperopt.tpe - INFO - TPE using 35/35 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005468 seconds\n",
      "hyperopt.tpe - INFO - TPE using 36/36 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004433 seconds\n",
      "hyperopt.tpe - INFO - TPE using 37/37 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005181 seconds\n",
      "hyperopt.tpe - INFO - TPE using 38/38 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004515 seconds\n",
      "hyperopt.tpe - INFO - TPE using 39/39 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004758 seconds\n",
      "hyperopt.tpe - INFO - TPE using 40/40 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004514 seconds\n",
      "hyperopt.tpe - INFO - TPE using 41/41 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004799 seconds\n",
      "hyperopt.tpe - INFO - TPE using 42/42 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004341 seconds\n",
      "hyperopt.tpe - INFO - TPE using 43/43 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007983 seconds\n",
      "hyperopt.tpe - INFO - TPE using 44/44 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004550 seconds\n",
      "hyperopt.tpe - INFO - TPE using 45/45 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005930 seconds\n",
      "hyperopt.tpe - INFO - TPE using 46/46 trials with best loss 0.184063\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004534 seconds\n",
      "hyperopt.tpe - INFO - TPE using 47/47 trials with best loss 0.184063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.004748 seconds\n",
      "hyperopt.tpe - INFO - TPE using 48/48 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004590 seconds\n",
      "hyperopt.tpe - INFO - TPE using 49/49 trials with best loss 0.184063\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 67%|██████▋   | 2/3 [03:47<01:53, 113.69s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.095468560708176,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=20,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=False, warm_start=False) - 0.8215488215488215\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=28, p=2,\n",
      "           weights='uniform') - 0.8170594837261503\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7917251548347687,\n",
      "       colsample_bytree=0.5911665753170415, gamma=0.000850685831907235,\n",
      "       learning_rate=0.00021537512357892256, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=3, missing=None, n_estimators=5400, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.032369166812364965, reg_lambda=3.435879530209204,\n",
      "       scale_pos_weight=1, seed=1, silent=True,\n",
      "       subsample=0.5046229877657071) - 0.8159371492704827\n",
      "100%|██████████| 3/3 [03:47<00:00, 75.79s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.095468560708176,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=20,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=False, warm_start=False) 0.8215488215488215\n",
      "(891, 20)\n"
     ]
    }
   ],
   "source": [
    "context, pipeline_data = LocalExecutor(pipeline_data.dataset, epochs=1) << \\\n",
    "    (Pipeline()\n",
    "     >> PipelineStep('model space', ModelSpace(model_list), initializer=True)\n",
    "     >> Hyperopt(CV(scoring=make_scorer(accuracy_score)), max_evals=50)\n",
    "     >> ChooseBest(1))\n",
    "\n",
    "for result in pipeline_data.return_val:\n",
    "    print(result.model, result.score)\n",
    "print(pipeline_data.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got a nice improvement. That's enough to get into the top 1% in the Kaggle Titatic demo competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting feature selection\n",
    "\n",
    "AutoML also allows you to select feature that perform well for the most models in the model space. Features that have geather importance in multiple models will have geather weight.\n",
    "\n",
    "\n",
    "First $N$ features are selected from the following well-ordered set:\n",
    "\n",
    "$\\mathbb{F} = softmax(\\mathbb{I}) \\circ \\mathbb{S}$,\n",
    "\n",
    "where \n",
    "* $\\mathbb{I} \\in \\mathbb{R}$ represents a model-specific feature score set\n",
    "* $\\mathbb{S} \\in \\mathbb{R}$ is a set of model scores according to some scoring function $s(x, m): \\mathbb{M} \\rightarrow \\mathbb{R} $ ($x$ is a dataset, $m$ is a model, $\\mathbb{M}$ is a model space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.5\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'IsAlone']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 9, new feature number - 10\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006940 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗\n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║\n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║\n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║\n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004785 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.28s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5723801254995939,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=30, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.7856341189674524\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.8511452661753225,\n",
      "       colsample_bytree=0.9697219347602777, gamma=0.002537592019027662,\n",
      "       learning_rate=0.0054536729589094194, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=6, missing=None, n_estimators=4000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.005977660001479486, reg_lambda=2.0631155769106613,\n",
      "       scale_pos_weight=1, seed=1, silent=True,\n",
      "       subsample=0.812209288374935) - 0.809203142536476\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #2\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'Age', 'Embarked', 'FamilySize']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004122 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007173 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.12it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7562288392967507,\n",
      "       colsample_bytree=0.9616788709893351, gamma=0.002097959881727001,\n",
      "       learning_rate=0.008681052013255468, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=33, missing=None, n_estimators=4000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=4.879267052003685e-06, reg_lambda=1.256833611315617,\n",
      "       scale_pos_weight=1, seed=2, silent=True,\n",
      "       subsample=0.816921249051437) - 0.7755331088664422\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.5735711597402272,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=11, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.7811447811447811\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.39it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #3\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'Age', 'FamilySize', '(Pclass_mul_Sex)']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004261 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004605 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:01<00:01,  1.70it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.9850874752008347,\n",
      "       colsample_bytree=0.6564900316641631, gamma=0.10876807548294232,\n",
      "       learning_rate=0.0004325663616031183, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=66, missing=None, n_estimators=6000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.11458809561923787, reg_lambda=1.2379096181902154,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.6596697003171195) - 0.6161616161616161\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=142, n_jobs=1,\n",
      "            oob_score=False, random_state=3, verbose=False,\n",
      "            warm_start=False) - 0.819304152637486\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.72it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #4\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'FamilySize', '(Pclass_mul_Sex)', '(Sex_add_FamilySize)']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006221 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004761 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:02<00:01,  1.29it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.15827015830444757,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=174, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=False, warm_start=False) - 0.7912457912457912\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.6745330751353295,\n",
      "       colsample_bytree=0.5625897752910944, gamma=9.754802182135838e-05,\n",
      "       learning_rate=0.034852873911809, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=2, missing=None, n_estimators=3400, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.007509479670434204, reg_lambda=1.0458471918837668,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.671043103767281) - 0.7912457912457912\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.96it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #5\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'FamilySize', '(Pclass_mul_Sex)', '(Sex_add_FamilySize)']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004765 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004131 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:01,  1.60it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.8132079355507038,\n",
      "       colsample_bytree=0.7229112540223576, gamma=0.0011881315904272904,\n",
      "       learning_rate=0.000546077539864241, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=33, missing=None, n_estimators=5000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.03551121080733793, reg_lambda=1.4999454203143583,\n",
      "       scale_pos_weight=1, seed=2, silent=True,\n",
      "       subsample=0.788327214362534) - 0.7867564534231201\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.43088429080032586,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=102, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=False, warm_start=False) - 0.7912457912457912\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.53it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #6\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'FamilySize', '(Pclass_mul_Sex)', '(Pclass_mul_(Pclass_mul_Sex))']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004292 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004308 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:02<00:01,  1.19it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.8066441981374401,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=12,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=40, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=False, warm_start=False) - 0.787878787878788\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.6278540509498391,\n",
      "       colsample_bytree=0.8915928912594195, gamma=1.0209993976617292e-05,\n",
      "       learning_rate=0.016400827995889655, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=2, missing=None, n_estimators=4600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.00717185016742254, reg_lambda=1.0512097586525666,\n",
      "       scale_pos_weight=1, seed=2, silent=True,\n",
      "       subsample=0.5027115780143658) - 0.7890011223344556\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.81it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #7\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', 'FamilySize', '(Pclass_mul_Sex)', '(Pclass_mul_(Pclass_mul_Sex))']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004230 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004492 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.11it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.9338550198629243,\n",
      "       colsample_bytree=0.517425157676277, gamma=0.01569245191253715,\n",
      "       learning_rate=0.0020322247949656523, max_delta_step=0, max_depth=1,\n",
      "       min_child_weight=82, missing=None, n_estimators=5000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.0030643575289182362, reg_lambda=1.21483195832067,\n",
      "       scale_pos_weight=1, seed=1, silent=True,\n",
      "       subsample=0.9871713596877072) - 0.6161616161616161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=0.27398126117665655,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=5,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=13, n_jobs=1, oob_score=False, random_state=1,\n",
      "            verbose=False, warm_start=False) - 0.8002244668911335\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.39it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #8\n",
      "LocalExecutor - INFO - Dataset columns: ['Pclass', 'Sex', '(Pclass_mul_Sex)', '(Pclass_mul_(Pclass_mul_Sex))', '((Pclass_mul_Sex)_add_FamilySize)']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005614 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005067 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:01<00:01,  1.53it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7940789198322706,\n",
      "       colsample_bytree=0.9795587490207813, gamma=0.0014572746029580853,\n",
      "       learning_rate=0.09366628020337191, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=15, missing=None, n_estimators=4800, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.029835218725883, reg_lambda=1.7319358304641488,\n",
      "       scale_pos_weight=1, seed=1, silent=True,\n",
      "       subsample=0.5386394852554568) - 0.7934904601571269\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=0.3565983234685056,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=21,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=32, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.8103254769921436\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.42it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #9\n",
      "LocalExecutor - INFO - Dataset columns: ['Sex', '(Pclass_mul_Sex)', '(Pclass_mul_(Pclass_mul_Sex))', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 5\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004464 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004241 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:07<00:04,  2.50s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=2871, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=False,\n",
      "            warm_start=False) - 0.787878787878788\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7990597491997172,\n",
      "       colsample_bytree=0.6213865843605919, gamma=0.1613131623336069,\n",
      "       learning_rate=0.1672231074864452, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=5, missing=None, n_estimators=2000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.0353176345343149, reg_lambda=2.6823387925102113,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.8874691927668606) - 0.7957351290684626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.56s/it]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #10\n",
      "LocalExecutor - INFO - Dataset columns: ['Sex', '(Pclass_mul_Sex)', '(Pclass_mul_(Pclass_mul_Sex))', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003849 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004321 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.42it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=48, n_jobs=1,\n",
      "            oob_score=False, random_state=4, verbose=False,\n",
      "            warm_start=False) - 0.8013468013468014\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.8443958954210677,\n",
      "       colsample_bytree=0.9340779137512399, gamma=7.384619532718377e-05,\n",
      "       learning_rate=0.02699020998718412, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=11, missing=None, n_estimators=600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.05826294038579968, reg_lambda=1.9406469525748387,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.5376562657779921) - 0.8013468013468014\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.51it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #11\n",
      "LocalExecutor - INFO - Dataset columns: ['Sex', '(Pclass_mul_Sex)', '(Pclass_mul_(Pclass_mul_Sex))', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004596 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004835 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:02<00:01,  1.38it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.8466015163610753,\n",
      "       colsample_bytree=0.7329296338608442, gamma=0.09993203150109717,\n",
      "       learning_rate=0.024839140603828816, max_delta_step=0, max_depth=1,\n",
      "       min_child_weight=92, missing=None, n_estimators=1400, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=6.441770366411705e-05, reg_lambda=1.0049445973427265,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.5720492741590806) - 0.6161616161616161\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=572, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=False,\n",
      "            warm_start=False) - 0.7890011223344557\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "/usr/local/lib/python3.6/site-packages/xgboost/sklearn.py:385: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return all_features / all_features.sum()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.23it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #12\n",
      "LocalExecutor - INFO - Dataset columns: ['Sex', '(Pclass_mul_Sex)', '(Pclass_mul_(Pclass_mul_Sex))', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 6, new feature number - 7\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004015 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005416 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.25s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.46065998056860513,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=109, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=False, warm_start=False) - 0.7833894500561168\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7280304539053164,\n",
      "       colsample_bytree=0.9299932975752938, gamma=0.0006532103538180599,\n",
      "       learning_rate=0.016088100571855113, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=1, missing=None, n_estimators=5600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.4201774569786826, reg_lambda=2.184740684338026,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.688240441183191) - 0.7923681257014591\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.23it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #13\n",
      "LocalExecutor - INFO - Dataset columns: ['(Pclass_mul_Sex)', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '(Sex_mul_(Pclass_mul_Sex))']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 5\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004502 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004907 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.76it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=12, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=27, n_jobs=1,\n",
      "            oob_score=False, random_state=2, verbose=False,\n",
      "            warm_start=False) - 0.7968574635241302\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.6690223651579716,\n",
      "       colsample_bytree=0.8845261584404343, gamma=0.4584485441923799,\n",
      "       learning_rate=0.014959469648166556, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.31789608439673983, reg_lambda=2.4081963824536503,\n",
      "       scale_pos_weight=1, seed=0, silent=True,\n",
      "       subsample=0.7573447355933951) - 0.7968574635241302\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.99it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #14\n",
      "LocalExecutor - INFO - Dataset columns: ['(Pclass_mul_Sex)', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '(Sex_mul_(Pclass_mul_Sex))']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005945 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006298 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.04it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.4434927092617287,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=33, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.7856341189674523\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.6621217269111761,\n",
      "       colsample_bytree=0.7320153478423315, gamma=0.505299103546863,\n",
      "       learning_rate=0.00861950079144309, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=2, missing=None, n_estimators=1000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.006981305224600569, reg_lambda=2.7124495974127383,\n",
      "       scale_pos_weight=1, seed=0, silent=True,\n",
      "       subsample=0.9173529433751699) - 0.8002244668911337\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.84it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #15\n",
      "LocalExecutor - INFO - Dataset columns: ['(Pclass_mul_Sex)', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 5\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004581 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005108 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:01<00:01,  1.95it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7822766056063729,\n",
      "       colsample_bytree=0.8781445630913404, gamma=3.184981510895124e-05,\n",
      "       learning_rate=0.3313984073574449, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=1, missing=None, n_estimators=2000, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.006772715779410485, reg_lambda=1.123929127022533,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.7813572427586273) - 0.7923681257014591\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=0.035248677804027184,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=28, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.8103254769921436\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.91it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #16\n",
      "LocalExecutor - INFO - Dataset columns: ['(Pclass_mul_Sex)', '((Pclass_mul_Sex)_add_FamilySize)', '(Sex_add_Pclass)', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004142 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005445 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.08it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.8038801203295001,\n",
      "       colsample_bytree=0.8135342605163527, gamma=0.06132989281302969,\n",
      "       learning_rate=3.064054760412207e-05, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=4, missing=None, n_estimators=1400, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.00795775701826773, reg_lambda=3.75688857231133,\n",
      "       scale_pos_weight=1, seed=1, silent=True,\n",
      "       subsample=0.7371682767822296) - 0.7923681257014591\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=4, max_features=0.4896357504824057,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=242, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=False, warm_start=False) - 0.8013468013468014\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.28it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #17\n",
      "LocalExecutor - INFO - Dataset columns: ['(Pclass_mul_Sex)', '((Pclass_mul_Sex)_add_FamilySize)', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))))']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004539 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006667 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.97it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7602527905468304,\n",
      "       colsample_bytree=0.6765811020810293, gamma=0.13525387820850263,\n",
      "       learning_rate=0.029779096135010685, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=54, missing=None, n_estimators=400, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.012990184825404252, reg_lambda=1.3310445554434522,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.7601360781207979) - 0.6161616161616161\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.806162653816098,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=79, n_jobs=1, oob_score=False, random_state=3,\n",
      "            verbose=False, warm_start=False) - 0.7912457912457912\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.47it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #18\n",
      "LocalExecutor - INFO - Dataset columns: ['(Pclass_mul_Sex)', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))))', '((Pclass_mul_Sex)_sub_((Pclass_mul_Sex)_add_FamilySize))']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004647 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005926 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:02<00:01,  1.10it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.5663117224530831,\n",
      "       colsample_bytree=0.5314535744624317, gamma=0.9990038219106372,\n",
      "       learning_rate=0.09900604727937809, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=46, missing=None, n_estimators=1600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.6395590704387456, reg_lambda=3.2442891817283663,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.9262151577250355) - 0.7497194163860831\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=767, n_jobs=1,\n",
      "            oob_score=False, random_state=2, verbose=False,\n",
      "            warm_start=False) - 0.7912457912457912\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.78it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #19\n",
      "LocalExecutor - INFO - Dataset columns: ['((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))))', '((Pclass_mul_Sex)_sub_((Pclass_mul_Sex)_add_FamilySize))', '(((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))_mul_(Pclass_mul_Sex))']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004026 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004768 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:02<00:01,  1.07it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.6354082911095608,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=101, n_jobs=1, oob_score=False, random_state=3,\n",
      "            verbose=False, warm_start=False) - 0.7912457912457912\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.8674970551474502,\n",
      "       colsample_bytree=0.52343840899682, gamma=1.409547202004957,\n",
      "       learning_rate=0.0011308843507627719, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=1, missing=None, n_estimators=4600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=6.94331464150541e-05, reg_lambda=3.766376256806114,\n",
      "       scale_pos_weight=1, seed=2, silent=True,\n",
      "       subsample=0.9494724189491892) - 0.8002244668911335\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #20\n",
      "LocalExecutor - INFO - Dataset columns: ['((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))', '((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))', '((Sex_add_Pclass)_add_((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))))', '((Pclass_mul_Sex)_sub_((Pclass_mul_Sex)_add_FamilySize))', '(((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))_add_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))))']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 5, new feature number - 6\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x116a12b38>, 'max_features': <hyperopt.pyll.base.Apply object at 0x116a12ef0>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x116b91780>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x116b91128>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x116b91b00>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x116b915c0>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003793 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {}\n",
      "Hyperopt - WARNING - Skipping hyperopt step for model <class 'sklearn.linear_model.logistic.LogisticRegression'>. No parameter templats found\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x116b914a8>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x116b91ba8>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x116b91da0>, 'gamma': <hyperopt.pyll.base.Apply object at 0x116b91f28>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x116b9e278>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x116b9eac8>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x116b9ec50>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x116b9ec18>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x116b9e828>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x116b9efd0>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x116b9ea58>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004488 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.02it/s]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - <class 'sklearn.linear_model.logistic.LogisticRegression'> - 0\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.5010372927131221,\n",
      "       colsample_bytree=0.6363781436333136, gamma=1.4143689967206658,\n",
      "       learning_rate=0.0006961769815068519, max_delta_step=0, max_depth=1,\n",
      "       min_child_weight=51, missing=None, n_estimators=4800, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=7.514229992362662e-06, reg_lambda=2.644368927737067,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.9947229032889922) - 0.7463524130190797\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.16941997001422793,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=13,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=154, n_jobs=1, oob_score=False, random_state=3,\n",
      "            verbose=False, warm_start=False) - 0.7957351290684626\n",
      "LocalExecutor - INFO - Running step 'VotingFeatureSelector'\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'> 0\n",
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.5010372927131221,\n",
      "       colsample_bytree=0.6363781436333136, gamma=1.4143689967206658,\n",
      "       learning_rate=0.0006961769815068519, max_delta_step=0, max_depth=1,\n",
      "       min_child_weight=51, missing=None, n_estimators=4800, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=7.514229992362662e-06, reg_lambda=2.644368927737067,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.9947229032889922) 0.7463524130190797\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=0.16941997001422793,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=13,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=154, n_jobs=1, oob_score=False, random_state=3,\n",
      "            verbose=False, warm_start=False) 0.7957351290684626\n",
      "(891, 5)\n",
      "Selected features:\n",
      "((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))\n",
      "((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))\n",
      "((Sex_add_Pclass)_add_((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))))\n",
      "(((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))_add_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_mul_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))))\n",
      "(((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize))_add_((Sex_add_Pclass)_add_((Pclass_mul_Sex)_add_FamilySize)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from automl.hyperparam.optimization import Hyperopt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from automl.feature.selector import VotingFeatureSelector\n",
    "from automl.feature.generators import FormulaFeatureGenerator\n",
    "\n",
    "model_list = [\n",
    "      (RandomForestClassifier, random_forest_hp_space()),\n",
    "      (LogisticRegression, {}),\n",
    "      (XGBClassifier, xgboost_hp_space())\n",
    "  ]\n",
    "\n",
    "dataset = preprocess_data(data)\n",
    "\n",
    "context, pipeline_data = LocalExecutor(dataset, epochs=20) << \\\n",
    "    (Pipeline()\n",
    "     >> PipelineStep('model space', ModelSpace(model_list), initializer=True)\n",
    "     >> FormulaFeatureGenerator()\n",
    "     >> Hyperopt(CV(scoring=make_scorer(accuracy_score)), max_evals=1)\n",
    "     >> ChooseBest(4, by_largest_score=False)\n",
    "     >> VotingFeatureSelector(feature_to_select=5, reverse_score=True))\n",
    "\n",
    "for result in pipeline_data.return_val:\n",
    "    print(result.model, result.score)\n",
    "print(pipeline_data.dataset.data.shape)\n",
    "\n",
    "print(f\"Selected features:\")\n",
    "for col in pipeline_data.dataset.columns:\n",
    "    print(f\"{col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 features were selected from an initial set on 9.\n",
    "\n",
    "# Reproducable preprocessing\n",
    "After you're done with AutoML model search it may be useful to reproduce resulting feature generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   6.,   6.,  36.,  38.],\n",
       "       [  3.,   6.,   1.,   6.,   9.],\n",
       "       [  4.,   8.,   3.,  24.,  28.],\n",
       "       ..., \n",
       "       [  7.,  14.,   3.,  42.,  49.],\n",
       "       [ -3.,  -3.,   5., -15., -18.],\n",
       "       [ -1.,   1.,   7.,   7.,   6.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from automl.feature.generators import Preprocessing\n",
    "\n",
    "original_dataset = preprocess_data(data)\n",
    "\n",
    "# Let's recreate all features useful features found in AutoML Pipeline\n",
    "preprocessing = Preprocessing()\n",
    "final_data = preprocessing.reproduce(pipeline_data.dataset, original_dataset)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
