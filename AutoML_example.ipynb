{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnePanel AutoML 0.1a\n",
    "\n",
    "AutoML is a framework that allows building automated machine learning pipelines easily and declaratively, running them locally (current implementation) or on the cluster (TBD).\n",
    "\n",
    "The framework can be easily extened with new features.\n",
    "Currently AutoML is integrated with popular opensource machine learning libraries like Scikit-learn and Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# AutoML uses Python's logging module\n",
    "import logging\n",
    "\n",
    "# Various sklearn models and metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# AutoML Clasees\n",
    "from automl.pipeline import LocalExecutor, Pipeline, PipelineStep, PipelineData\n",
    "from automl.data.dataset import Dataset\n",
    "from automl.model import ModelSpace, CV, Validate, ChooseBest\n",
    "from automl.hyperparam.templates import (random_forest_hp_space, \n",
    "                                         knn_hp_space, svc_kernel_hp_space, \n",
    "                                         grad_boosting_hp_space, \n",
    "                                         xgboost_hp_space)\n",
    "from automl.feature.generators import FormulaFeatureGenerator\n",
    "from automl.feature.selector import FeatureSelector\n",
    "from automl.hyperparam.optimization import Hyperopt\n",
    "from automl.combinators import RandomChoice\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core concepts\n",
    "AutoML follows code-is-data and data-is-code philosophy. You defind automated machine learning pipelines as data structures that can be executed later.\n",
    "Key concepts in AutoML are \n",
    "* `Pipeline` - a machine learning pipeline. It executes various steps inside the pipeline passing each step output as an input to the next step\n",
    "* `PipelineStep` - all `Pipeline`s consist of steps. AutoML provide lots of different steps out of the box\n",
    "* `Executor` - executes a pipeline. Currently AutoML provides `LocalExecutor` which runs pipeline locally. Future versions will have `DistributedExecutor` built-in \n",
    "\n",
    "AutoML can easily be extended by implementing own `PipelineStep`s. Next, we will use various built-in `PipelineStep`s to create an automated classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.4\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "LocalExecutor - INFO - Dataset columns: ['base_feature_0', 'base_feature_1', 'base_feature_2', 'base_feature_3', 'base_feature_4', 'base_feature_5', 'base_feature_6', 'base_feature_7', 'base_feature_8', 'base_feature_9', 'base_feature_10', 'base_feature_11', 'base_feature_12', 'base_feature_13', 'base_feature_14', 'base_feature_15', 'base_feature_16', 'base_feature_17', 'base_feature_18', 'base_feature_19', 'base_feature_20', 'base_feature_21', 'base_feature_22', 'base_feature_23', 'base_feature_24', 'base_feature_25', 'base_feature_26', 'base_feature_27', 'base_feature_28', 'base_feature_29', 'base_feature_30', 'base_feature_31', 'base_feature_32', 'base_feature_33', 'base_feature_34', 'base_feature_35', 'base_feature_36', 'base_feature_37', 'base_feature_38', 'base_feature_39']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 40, new feature number - 41\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x10fa611d0>, 'max_features': <hyperopt.pyll.base.Apply object at 0x10fa61588>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x10fa61898>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x10fa61c50>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x10fa61da0>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x10fa61eb8>, 'verbose': False, 'criterion': 'gini'}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003657 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗     \n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║     \n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║     \n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║     \n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.005952 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.140902\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003445 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.140902\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004199 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.140902\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003421 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.140902\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'n_neighbors': <hyperopt.pyll.base.Apply object at 0x10fa6e0f0>, 'weights': <hyperopt.pyll.base.Apply object at 0x10fa6e208>, 'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'p': 2, 'metric_params': None, 'n_jobs': 1}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001388 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001173 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.181159\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001104 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.181159\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001099 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.181159\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001091 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.181159\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x10fa6e400>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x10fa6e588>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x10fa6e780>, 'gamma': <hyperopt.pyll.base.Apply object at 0x10fa6e908>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x10fa6eac8>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x10fa6ec18>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x10fa6ed68>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x10fa6eeb8>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x10fa75080>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x10fa75208>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x10fa752b0>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004240 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005396 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.148551\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004568 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.148551\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004377 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.148551\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003921 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.148551\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:58<00:38, 19.41s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=53, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=False,\n",
      "            warm_start=False) - 0.859098228663446\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.9368285835238139,\n",
      "       colsample_bytree=0.6552247440060817, gamma=0.001555546306254618,\n",
      "       learning_rate=0.013102663011670764, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=15, missing=None, n_estimators=5800, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.3807650367373771, reg_lambda=3.4755450028727437,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.6106348062051078) - 0.857487922705314\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n",
      "           weights='distance') - 0.818840579710145\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - INFO - Removing 10 features for model RandomForestClassifier\n",
      "100%|██████████| 5/5 [00:58<00:00, 11.65s/it]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #2\n",
      "LocalExecutor - INFO - Dataset columns: ['base_feature_5', 'base_feature_9', 'base_feature_10', 'base_feature_12', 'base_feature_13', 'base_feature_17', 'base_feature_21', 'base_feature_25', 'base_feature_37', 'base_feature_38']\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'FormulaFeatureGenerator'\n",
      "FormulaFeatureGenerator - INFO - Generated new features. Old feature number - 10, new feature number - 11\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - {'n_estimators': <hyperopt.pyll.base.Apply object at 0x10fa611d0>, 'max_features': <hyperopt.pyll.base.Apply object at 0x10fa61588>, 'max_depth': <hyperopt.pyll.base.Apply object at 0x10fa61898>, 'min_samples_split': 2, 'min_samples_leaf': <hyperopt.pyll.base.Apply object at 0x10fa61c50>, 'bootstrap': <hyperopt.pyll.base.Apply object at 0x10fa61da0>, 'oob_score': False, 'n_jobs': 1, 'random_state': <hyperopt.pyll.base.Apply object at 0x10fa61eb8>, 'verbose': False, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007389 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004729 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.173510\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003959 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.164251\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004595 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.140902\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004034 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.140902\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'n_neighbors': <hyperopt.pyll.base.Apply object at 0x10fa6e0f0>, 'weights': <hyperopt.pyll.base.Apply object at 0x10fa6e208>, 'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'p': 2, 'metric_params': None, 'n_jobs': 1}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001396 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001095 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.278180\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001100 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.185588\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001080 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.185588\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.001085 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.179549\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - {'max_depth': <hyperopt.pyll.base.Apply object at 0x10fa6e400>, 'learning_rate': <hyperopt.pyll.base.Apply object at 0x10fa6e588>, 'n_estimators': <hyperopt.pyll.base.Apply object at 0x10fa6e780>, 'gamma': <hyperopt.pyll.base.Apply object at 0x10fa6e908>, 'min_child_weight': <hyperopt.pyll.base.Apply object at 0x10fa6eac8>, 'max_delta_step': 0, 'subsample': <hyperopt.pyll.base.Apply object at 0x10fa6ec18>, 'colsample_bytree': <hyperopt.pyll.base.Apply object at 0x10fa6ed68>, 'colsample_bylevel': <hyperopt.pyll.base.Apply object at 0x10fa6eeb8>, 'reg_alpha': <hyperopt.pyll.base.Apply object at 0x10fa75080>, 'reg_lambda': <hyperopt.pyll.base.Apply object at 0x10fa75208>, 'scale_pos_weight': 1, 'base_score': 0.5, 'seed': <hyperopt.pyll.base.Apply object at 0x10fa752b0>}\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005408 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004305 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.120773\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004276 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.120773\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004385 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.120773\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004178 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.120773\n",
      "/Users/rush/Library/Python/3.6/lib/python/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      " 60%|██████    | 3/5 [00:15<00:10,  5.01s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7029171201164298,\n",
      "       colsample_bytree=0.8202498114564213, gamma=0.0002521774277090169,\n",
      "       learning_rate=0.030183394354278886, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=14, missing=None, n_estimators=3600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=1.8306493666902642e-05, reg_lambda=3.017614599509498,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.6676518104409546) - 0.8792270531400966\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=4, max_features=0.9024309096796727,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=7,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=2542, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.859098228663446\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=21, p=2,\n",
      "           weights='distance') - 0.820450885668277\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - INFO - Removing 10 features for model XGBClassifier\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.7029171201164298,\n",
      "       colsample_bytree=0.8202498114564213, gamma=0.0002521774277090169,\n",
      "       learning_rate=0.030183394354278886, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=14, missing=None, n_estimators=3600, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=1.8306493666902642e-05, reg_lambda=3.017614599509498,\n",
      "       scale_pos_weight=1, seed=3, silent=True,\n",
      "       subsample=0.6676518104409546) 0.8792270531400966\n",
      "(1000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's create a dataset first\n",
    "x, y = make_classification(\n",
    "      n_samples=1000,\n",
    "      n_features=40,\n",
    "      n_informative=2,\n",
    "      n_redundant=10,\n",
    "      flip_y=0.05)\n",
    "\n",
    "# We will use AutoML Dataset class to wrap our data \n",
    "# into structure that can be understanded by AutoML\n",
    "data = Dataset(x, y)\n",
    "\n",
    "# Next, we define our ModelSpace. ModelSpace is initialized by a list of tuples.\n",
    "# First element of each tuple should be an sklearn-like estimator with fit method\n",
    "# The second one is model parameter dictionary. Here we do not define parameters \n",
    "# explicitly, but use hyperparameter templates from AutoML. Those templates can be\n",
    "# used later by Hyperopt step to find best model parameters automatically\n",
    "model_list = [\n",
    "      (RandomForestClassifier, random_forest_hp_space()),\n",
    "      (KNeighborsClassifier, knn_hp_space(lambda key: key)),\n",
    "      (XGBClassifier, xgboost_hp_space())\n",
    "  ]\n",
    "\n",
    "\n",
    "# Create executor, initialize it with our classification dataset \n",
    "# and set total number of epochs to 2 (the pipeline will be run two times in a row).\n",
    "# We can load any pipeline into executor using << operator like below:\n",
    "context, pipeline_data = LocalExecutor(data, epochs=2) << \\\n",
    "    (Pipeline() # Here we define the pipeline. Steps can be added to pipeline using >> operator\n",
    "     # First we define our ModelSpace. We wrap it with PipelineStep class \n",
    "     # and set initializer=True so that ModelSpace step will be run only at the first epoch\n",
    "     >> PipelineStep('model space', ModelSpace(model_list), initializer=True)\n",
    "     # But we are not obliged to wrap all steps with PipelineStep.\n",
    "     # This will be done automatically if we do not need to set any special parameters \n",
    "     # We use FormulaFeatureGenerator to create arithmetic combinations of features from the dataset\n",
    "     >> FormulaFeatureGenerator(['+', '-', '*']) \n",
    "     # Next we use Hyperopt to find the best combination of hyperparameters for each model\n",
    "     # We use test set validation with ROC AUC metric as a score function.\n",
    "     # CV could be used instead of Validate to perform cross-validation\n",
    "     >> Hyperopt(Validate(test_size=0.1, metrics=roc_auc_score), max_evals=5) \n",
    "     # Then we choose the best performing model we found\n",
    "     >> ChooseBest(1)\n",
    "     # And select 10 best features\n",
    "     >> FeatureSelector(10))\n",
    "\n",
    "for result in pipeline_data.return_val:\n",
    "    print(result.model, result.score)\n",
    "print(pipeline_data.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending AutoML\n",
    "\n",
    "First, let's look at how `PipelineStep`s can be created by creating a simple hello world pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.4\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'hello_step'\n",
      "100%|██████████| 1/1 [00:00<00:00, 896.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗     \n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║     \n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║     \n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║     \n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n",
      "Hello!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<automl.pipeline.PipelineContext at 0x10a64f5c0>, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a simple pipeline\n",
    "pipeline = Pipeline() >> PipelineStep('hello_step', lambda inp, context: print(\"Hello!\"))\n",
    "\n",
    "# And execute it locally\n",
    "LocalExecutor() << pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see steps can be added to a pipeline using `>>` operator. A pipeline may contain any number of steps. Any `PipelineStep` is constructed by passing a step name and a `callable` which will be executed when `Pipeline` is run by an `Executor`. It's important to mention that all `Pipeline`s are lazy and all steps inside will be executed only when `Pipeline` is loaded into `Executor.`\n",
    "\n",
    "`PipelineStep` syntax is pretty verbose, but it can be simplified. You can pass any `callable` to a pipeline and it will be wrapped into `PipelineStep` automatically. Step function should have two arguments: `input` and `context`. `input` must be loaded through executor parameters, `context` contains global variables, available for each step. If `PipelineStep` returns any value, it should wrap it into `PipelineData` class. `input` passed to an `Executor` is wrapped to `PipelineData` automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.4\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'RandomChoice'\n",
      "100%|██████████| 1/1 [00:00<00:00, 771.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗     \n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║     \n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║     \n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║     \n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<automl.pipeline.PipelineContext at 0x110182ac8>, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create two steps that add 1 and 2 to input data\n",
    "plus_one = PipelineStep('plus_one', lambda inp, context: inp.dataset + 1)\n",
    "plus_two = PipelineStep('plus_two', lambda inp, context: inp.dataset + 2)\n",
    "\n",
    "LocalExecutor(0) << \\\n",
    "    (Pipeline()\n",
    "     # We use RandomChoice combinator to choose randomly between two steps while executing the pipeline\n",
    "     >> RandomChoice([plus_one, plus_two]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to create complex callables for `PipelineStep`s as classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Framework version: v0.1.4\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'ComplexStep'\n",
      "100%|██████████| 1/1 [00:00<00:00, 530.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ComplexStep\n",
      "\n",
      "  █████╗ ██╗   ██╗████████╗ ██████╗ ███╗   ███╗██╗     \n",
      " ██╔══██╗██║   ██║╚══██╔══╝██╔═══██╗████╗ ████║██║     \n",
      " ███████║██║   ██║   ██║   ██║   ██║██╔████╔██║██║     \n",
      " ██╔══██║██║   ██║   ██║   ██║   ██║██║╚██╔╝██║██║     \n",
      " ██║  ██║╚██████╔╝   ██║   ╚██████╔╝██║ ╚═╝ ██║███████╗\n",
      " ╚═╝  ╚═╝ ╚═════╝    ╚═╝    ╚═════╝ ╚═╝     ╚═╝╚══════╝\n",
      "\n",
      "<automl.pipeline.PipelineData object at 0x110182208>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<automl.pipeline.PipelineContext at 0x110182438>,\n",
       " <automl.pipeline.PipelineData at 0x110182208>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ComplexStep:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing ComplexStep\")\n",
    "        \n",
    "    def __call__(self, inp, context):\n",
    "        print(inp)\n",
    "        return inp\n",
    "    \n",
    "LocalExecutor() << (Pipeline() >> ComplexStep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
