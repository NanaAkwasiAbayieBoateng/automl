{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onepanel AutoML 0.1a - Kaggle Dataset Example\n",
    "\n",
    "Here we use AutoML to solve a classification task on a classic [Titanic](https://www.kaggle.com/c/titanic) dataset from Kaggle. First, let's download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived Pclass  \\\n",
       "0            1         0      3   \n",
       "1            2         1      1   \n",
       "2            3         1      3   \n",
       "3            4         1      1   \n",
       "4            5         0      3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/train.csv', parse_dates=[2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "# AutoML uses Python's logging module\n",
    "import logging\n",
    "\n",
    "# Various sklearn models and metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, make_scorer\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# AutoML Clasees\n",
    "from automl.pipeline import LocalExecutor, Pipeline, PipelineStep, PipelineData\n",
    "from automl.data.dataset import Dataset\n",
    "from automl.model import ModelSpace, CV, Validate, ChooseBest\n",
    "from automl.hyperparam.templates import (random_forest_hp_space, \n",
    "                                         knn_hp_space, svc_hp_space, \n",
    "                                         grad_boosting_hp_space, \n",
    "                                         xgboost_hp_space)\n",
    "from automl.feature.generators import FormulaFeatureGenerator, PolynomialGenerator\n",
    "from automl.feature.selector import FeatureSelector\n",
    "from automl.hyperparam.hyperopt import Hyperopt\n",
    "from automl.combinators import RandomChoice\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "# ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how automated our process is, data still may need some preprocessing. Also, doing good old feature engenering can help by a lot. We skip exploratory data analysis and feature engeneering stages for brevity. If you are interested, we suggest looking up some examples at contest's [kernels](https://www.kaggle.com/c/titanic/kernels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  FamilySize  IsAlone\n",
       "0       3    1    2      1      0     0         2           2        0\n",
       "1       1    0    4      1      0     1         0           2        0\n",
       "2       3    0    3      0      0     0         2           1        1\n",
       "3       1    0    4      1      0     1         2           2        0\n",
       "4       3    1    4      0      0     0         2           1        1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess data and create AutoML Dataset\"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    result = df.copy()\n",
    "    \n",
    "    # drop columns we won't be using\n",
    "    result.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "    \n",
    "    # transform Sex column into numeric categories\n",
    "    result['Sex'] = encoder.fit_transform(result['Sex'])\n",
    "    \n",
    "    # do the same with Embarked column\n",
    "    result['Embarked'] = encoder.fit_transform(result['Embarked'].astype(str))\n",
    "    \n",
    "    # Replace missing Ages with median value and \"pack\"\n",
    "    # Age into 10 equal-sized bins. For example, all \n",
    "    # ages from 0-10 will be packed into bin 0.\n",
    "    result['Age'].fillna(result['Age'].median(), inplace=True)\n",
    "    result['Age'] = pd.cut(result['Age'], 10, labels=range(0,10)).astype(int)\n",
    "    \n",
    "    # Pack Fare into 10 bins\n",
    "    result['Fare'] = pd.cut(result['Fare'], 10, labels=range(0,10)).astype(int)\n",
    "    \n",
    "    # transform Pclass type to int\n",
    "    result['Pclass'] = result['Pclass'].astype(int)\n",
    "    \n",
    "    # add some useful predictive features that may came \n",
    "    # up to mind during data analysis\n",
    "    result['FamilySize'] = result['SibSp'] + result['Parch'] + 1\n",
    "    result['IsAlone'] = 0\n",
    "    result.loc[result['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "    return Dataset(result.drop(['Survived'], axis=1),\n",
    "                   result['Survived'])\n",
    "\n",
    "dataset = preprocess_data(data)\n",
    "dataset.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit simple XGBoost model with default parameters and see how it scores on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81940713961728329"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rf = XGBClassifier()\n",
    "np.mean(cross_val_score(rf, dataset.data, dataset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, 81% accuracy with the defaults. Let's go on to AutoML Pipelines and see if we can improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "LocalExecutor - INFO - Running step 'SklearnFeatureGenerator'\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005084 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005467 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008861 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.177329\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007315 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.177329\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006723 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.177329\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005921 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.177329\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005519 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.177329\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005877 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005858 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006621 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006042 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005827 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005701 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005909 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005408 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005762 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006118 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006525 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005139 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.009898 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.175084\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.8249158249158248\n",
      "Hyperopt - INFO - 0.8226711560044894\n",
      "Hyperopt - INFO - 0.8226711560044894\n",
      "Hyperopt - INFO - 0.8125701459034792\n",
      "Hyperopt - INFO - 0.809203142536476\n",
      "Hyperopt - INFO - 0.8080808080808081\n",
      "Hyperopt - INFO - 0.8047138047138048\n",
      "Hyperopt - INFO - 0.8035914702581369\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8002244668911335\n",
      "Hyperopt - INFO - 0.7991021324354657\n",
      "Hyperopt - INFO - 0.7946127946127947\n",
      "Hyperopt - INFO - 0.7946127946127947\n",
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7901234567901234\n",
      "Hyperopt - INFO - 0.787878787878788\n",
      "Hyperopt - INFO - 0.7867564534231201\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004146 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004350 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.287318\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004287 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.271605\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003974 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.271605\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003707 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.236813\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005318 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.234568\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004302 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.234568\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008907 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.234568\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004395 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.225589\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004513 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004325 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005547 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004613 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005138 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004447 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004668 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004082 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004135 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003907 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.217733\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007371 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.217733\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.7822671156004489\n",
      "Hyperopt - INFO - 0.7744107744107743\n",
      "Hyperopt - INFO - 0.7732884399551065\n",
      "Hyperopt - INFO - 0.7676767676767677\n",
      "Hyperopt - INFO - 0.7654320987654321\n",
      "Hyperopt - INFO - 0.7654320987654321\n",
      "Hyperopt - INFO - 0.7631874298540965\n",
      "Hyperopt - INFO - 0.7609427609427609\n",
      "Hyperopt - INFO - 0.7564534231200898\n",
      "Hyperopt - INFO - 0.7564534231200898\n",
      "Hyperopt - INFO - 0.7530864197530865\n",
      "Hyperopt - INFO - 0.7530864197530865\n",
      "Hyperopt - INFO - 0.7530864197530863\n",
      "Hyperopt - INFO - 0.7519640852974186\n",
      "Hyperopt - INFO - 0.7351290684624018\n",
      "Hyperopt - INFO - 0.7351290684624018\n",
      "Hyperopt - INFO - 0.7283950617283951\n",
      "Hyperopt - INFO - 0.712682379349046\n",
      "Hyperopt - INFO - 0.712682379349046\n",
      "Hyperopt - INFO - 0.6722783389450057\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006803 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006257 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006493 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005758 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006725 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006923 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006006 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006376 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006599 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006910 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006010 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006188 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.191919\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006788 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006775 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006480 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008462 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.184063\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007967 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.180696\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005892 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.180696\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005975 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.180696\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006619 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.180696\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.819304152637486\n",
      "Hyperopt - INFO - 0.8159371492704826\n",
      "Hyperopt - INFO - 0.8148148148148149\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8125701459034792\n",
      "Hyperopt - INFO - 0.8080808080808081\n",
      "Hyperopt - INFO - 0.8069584736251403\n",
      "Hyperopt - INFO - 0.8069584736251403\n",
      "Hyperopt - INFO - 0.8069584736251403\n",
      "Hyperopt - INFO - 0.8058361391694725\n",
      "Hyperopt - INFO - 0.7968574635241302\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7912457912457912\n",
      "Hyperopt - INFO - 0.7912457912457912\n",
      "Hyperopt - INFO - 0.7912457912457912\n",
      "Hyperopt - INFO - 0.787878787878788\n",
      "Hyperopt - INFO - 0.7833894500561168\n",
      "Hyperopt - INFO - 0.7811447811447811\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      " 60%|██████    | 3/5 [01:04<00:42, 21.48s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=325, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=False,\n",
      "            warm_start=False) - 0.8249158249158248\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, colsample_bylevel=0.9289862122316215,\n",
      "       colsample_bytree=0.8852975026805883, gamma=0.00043925295863166326,\n",
      "       learning_rate=0.00020077705022680114, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=7, missing=None, n_estimators=1000, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.03516919739830262,\n",
      "       reg_lambda=1.551323300561787, scale_pos_weight=1, seed=4,\n",
      "       silent=True, subsample=0.5665581074558654) - 0.819304152637486\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=38, p=1,\n",
      "           weights='distance') - 0.7822671156004489\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - INFO - Removing 19 features for model RandomForestClassifier\n",
      "100%|██████████| 5/5 [01:04<00:00, 12.98s/it]\n",
      "LocalExecutor - INFO - Starting AutoML Epoch #2\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "PipelineStep - INFO - Initializer step model space was already run, skipping\n",
      "LocalExecutor - INFO - Running step 'SklearnFeatureGenerator'\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004351 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005691 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.186308\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004723 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.186308\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008973 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005749 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006874 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005893 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006692 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005353 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004954 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006053 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008510 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005278 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005125 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005129 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.009298 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005436 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005218 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005548 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005076 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.175084\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.8249158249158249\n",
      "Hyperopt - INFO - 0.8249158249158249\n",
      "Hyperopt - INFO - 0.819304152637486\n",
      "Hyperopt - INFO - 0.8181818181818182\n",
      "Hyperopt - INFO - 0.8159371492704827\n",
      "Hyperopt - INFO - 0.8159371492704826\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8103254769921437\n",
      "Hyperopt - INFO - 0.8092031425364757\n",
      "Hyperopt - INFO - 0.8047138047138048\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.7957351290684623\n",
      "Hyperopt - INFO - 0.7946127946127947\n",
      "Hyperopt - INFO - 0.7946127946127945\n",
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7912457912457912\n",
      "Hyperopt - INFO - 0.7890011223344557\n",
      "Hyperopt - INFO - 0.7890011223344556\n",
      "Hyperopt - INFO - 0.7845117845117845\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003210 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003798 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.225589\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003766 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.216611\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003769 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.216611\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003952 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.216611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hyperopt.tpe - INFO - tpe_transform took 0.004017 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.216611\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003805 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.216611\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004434 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.216611\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004521 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004610 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004199 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003879 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003779 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003897 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004035 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004122 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003809 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003618 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003873 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.198653\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004672 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.198653\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.8013468013468014\n",
      "Hyperopt - INFO - 0.7890011223344556\n",
      "Hyperopt - INFO - 0.7845117845117846\n",
      "Hyperopt - INFO - 0.7845117845117846\n",
      "Hyperopt - INFO - 0.7833894500561168\n",
      "Hyperopt - INFO - 0.7833894500561168\n",
      "Hyperopt - INFO - 0.7822671156004489\n",
      "Hyperopt - INFO - 0.7744107744107745\n",
      "Hyperopt - INFO - 0.7665544332211\n",
      "Hyperopt - INFO - 0.7620650953984288\n",
      "Hyperopt - INFO - 0.7586980920314254\n",
      "Hyperopt - INFO - 0.7564534231200898\n",
      "Hyperopt - INFO - 0.7351290684624017\n",
      "Hyperopt - INFO - 0.7138047138047138\n",
      "Hyperopt - INFO - 0.7138047138047138\n",
      "Hyperopt - INFO - 0.7138047138047138\n",
      "Hyperopt - INFO - 0.6924803591470258\n",
      "Hyperopt - INFO - 0.6924803591470258\n",
      "Hyperopt - INFO - 0.6924803591470258\n",
      "Hyperopt - INFO - 0.6924803591470258\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006561 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006126 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.197531\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006343 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.012236 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008175 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006801 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006688 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006038 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006354 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006157 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007347 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.189675\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004971 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006997 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006229 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005866 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006767 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006815 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006049 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007105 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.188552\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006818 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.188552\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.8114478114478114\n",
      "Hyperopt - INFO - 0.8103254769921436\n",
      "Hyperopt - INFO - 0.8069584736251403\n",
      "Hyperopt - INFO - 0.8035914702581369\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8013468013468014\n",
      "Hyperopt - INFO - 0.8013468013468014\n",
      "Hyperopt - INFO - 0.8002244668911335\n",
      "Hyperopt - INFO - 0.7946127946127945\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7912457912457912\n",
      "Hyperopt - INFO - 0.7912457912457912\n",
      "Hyperopt - INFO - 0.7845117845117845\n",
      "Hyperopt - INFO - 0.7833894500561168\n",
      "Hyperopt - INFO - 0.7811447811447811\n",
      "Hyperopt - INFO - 0.7811447811447811\n",
      "Hyperopt - INFO - 0.7676767676767677\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      " 60%|██████    | 3/5 [02:48<01:52, 56.05s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=0.40674571689587147,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=37, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=False, warm_start=False) - 0.8249158249158249\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, colsample_bylevel=0.642158563576201,\n",
      "       colsample_bytree=0.6960522427332325, gamma=0.0037796762776710186,\n",
      "       learning_rate=0.004526306284936542, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=6, missing=None, n_estimators=2000, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.0006568851738268095,\n",
      "       reg_lambda=3.0278081303209556, scale_pos_weight=1, seed=1,\n",
      "       silent=True, subsample=0.7959752246006084) - 0.8114478114478114\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=1,\n",
      "           weights='uniform') - 0.8013468013468014\n",
      "LocalExecutor - INFO - Running step 'FeatureSelector'\n",
      "FeatureSelector - INFO - Removing 19 features for model RandomForestClassifier\n",
      "100%|██████████| 5/5 [02:48<00:00, 33.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=0.40674571689587147,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=2,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=37, n_jobs=1, oob_score=False, random_state=2,\n",
      "            verbose=False, warm_start=False) 0.8249158249158249\n",
      "(891, 19)\n"
     ]
    }
   ],
   "source": [
    "# Next, we define our ModelSpace. ModelSpace is initialized by a list of tuples.\n",
    "# First element of each tuple should be an sklearn-like estimator with fit method\n",
    "# The second one is model parameter dictionary. Here we do not define parameters \n",
    "# explicitly, but use hyperparameter templates from AutoML. Those templates can be\n",
    "# used later by Hyperopt step to find best model parameters automatically\n",
    "model_list = [\n",
    "      (RandomForestClassifier, random_forest_hp_space()),\n",
    "      (KNeighborsClassifier, knn_hp_space(lambda key: key)),\n",
    "      (XGBClassifier, xgboost_hp_space())\n",
    "  ]\n",
    "\n",
    "\n",
    "# Create executor, initialize it with our classification dataset \n",
    "# and set total number of epochs to 2 (the pipeline will be run two times in a row).\n",
    "# We can load any pipeline into executor using << operator like below:\n",
    "context, pipeline_data = LocalExecutor(dataset, epochs=2) << \\\n",
    "    (Pipeline() # Here we define the pipeline. Steps can be added to pipeline using >> operator\n",
    "     # First we define our ModelSpace. We wrap it with PipelineStep class \n",
    "     # and set initializer=True so that ModelSpace step will be run only at the first epoch\n",
    "     >> PipelineStep('model space', ModelSpace(model_list), initializer=True)\n",
    "     # But we are not obliged to wrap all steps with PipelineStep.\n",
    "     # This will be done automatically if we do not need to set any special parameters \n",
    "     # We use PolynomialGenerator to create polynomial combinations of the features from the dataset\n",
    "     >> PolynomialGenerator()\n",
    "     # Next we use Hyperopt to find the best combination of hyperparameters for each model\n",
    "     # We use test set validation with accuracy metric as a score function.\n",
    "     # CV could be used instead of Validate to perform cross-validation\n",
    "     >> Hyperopt(CV(scoring=make_scorer(accuracy_score)), max_evals=20)\n",
    "     # Then we choose the best performing model we found\n",
    "     >> ChooseBest(1)\n",
    "     # And select 10 best features\n",
    "     >> FeatureSelector(20))\n",
    "\n",
    "for result in pipeline_data.return_val:\n",
    "    print(result.model, result.score)\n",
    "print(pipeline_data.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have reached better accuracy compared to default XGBoost plain dataset. However, first pipeline we launched had a good job of generating various features for our dataset, but it was not really created for searching the best model. Now let's create a pipeline which will search for the best model on a fixed dataset.\n",
    "\n",
    "Please note that increasing `max_evals` parameter for `Hyperopt` can lead to finding better model parameters, but we use modest values here for demonstation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LocalExecutor - INFO - Starting AutoML Epoch #1\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]LocalExecutor - INFO - Running step 'model space'\n",
      "LocalExecutor - INFO - Running step 'Hyperopt'\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004551 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005586 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.205387\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007511 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.205387\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006692 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006507 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005235 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005579 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006115 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005615 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005600 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005058 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005680 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005367 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006960 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005179 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007300 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005142 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005305 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005503 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005613 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005456 seconds\n",
      "hyperopt.tpe - INFO - TPE using 20/20 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006263 seconds\n",
      "hyperopt.tpe - INFO - TPE using 21/21 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005579 seconds\n",
      "hyperopt.tpe - INFO - TPE using 22/22 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005251 seconds\n",
      "hyperopt.tpe - INFO - TPE using 23/23 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005237 seconds\n",
      "hyperopt.tpe - INFO - TPE using 24/24 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005210 seconds\n",
      "hyperopt.tpe - INFO - TPE using 25/25 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005297 seconds\n",
      "hyperopt.tpe - INFO - TPE using 26/26 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005333 seconds\n",
      "hyperopt.tpe - INFO - TPE using 27/27 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005208 seconds\n",
      "hyperopt.tpe - INFO - TPE using 28/28 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005507 seconds\n",
      "hyperopt.tpe - INFO - TPE using 29/29 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005655 seconds\n",
      "hyperopt.tpe - INFO - TPE using 30/30 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005231 seconds\n",
      "hyperopt.tpe - INFO - TPE using 31/31 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005644 seconds\n",
      "hyperopt.tpe - INFO - TPE using 32/32 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005439 seconds\n",
      "hyperopt.tpe - INFO - TPE using 33/33 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005889 seconds\n",
      "hyperopt.tpe - INFO - TPE using 34/34 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005372 seconds\n",
      "hyperopt.tpe - INFO - TPE using 35/35 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005259 seconds\n",
      "hyperopt.tpe - INFO - TPE using 36/36 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006368 seconds\n",
      "hyperopt.tpe - INFO - TPE using 37/37 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006257 seconds\n",
      "hyperopt.tpe - INFO - TPE using 38/38 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005611 seconds\n",
      "hyperopt.tpe - INFO - TPE using 39/39 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005668 seconds\n",
      "hyperopt.tpe - INFO - TPE using 40/40 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006409 seconds\n",
      "hyperopt.tpe - INFO - TPE using 41/41 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005074 seconds\n",
      "hyperopt.tpe - INFO - TPE using 42/42 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005493 seconds\n",
      "hyperopt.tpe - INFO - TPE using 43/43 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005174 seconds\n",
      "hyperopt.tpe - INFO - TPE using 44/44 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005295 seconds\n",
      "hyperopt.tpe - INFO - TPE using 45/45 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005223 seconds\n",
      "hyperopt.tpe - INFO - TPE using 46/46 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005605 seconds\n",
      "hyperopt.tpe - INFO - TPE using 47/47 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005302 seconds\n",
      "hyperopt.tpe - INFO - TPE using 48/48 trials with best loss 0.169473\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005361 seconds\n",
      "hyperopt.tpe - INFO - TPE using 49/49 trials with best loss 0.169473\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.830527497194164\n",
      "Hyperopt - INFO - 0.830527497194164\n",
      "Hyperopt - INFO - 0.830527497194164\n",
      "Hyperopt - INFO - 0.830527497194164\n",
      "Hyperopt - INFO - 0.830527497194164\n",
      "Hyperopt - INFO - 0.830527497194164\n",
      "Hyperopt - INFO - 0.8294051627384961\n",
      "Hyperopt - INFO - 0.8294051627384961\n",
      "Hyperopt - INFO - 0.8294051627384961\n",
      "Hyperopt - INFO - 0.8294051627384961\n",
      "Hyperopt - INFO - 0.8294051627384961\n",
      "Hyperopt - INFO - 0.8271604938271605\n",
      "Hyperopt - INFO - 0.8271604938271605\n",
      "Hyperopt - INFO - 0.8226711560044894\n",
      "Hyperopt - INFO - 0.8215488215488215\n",
      "Hyperopt - INFO - 0.8204264870931538\n",
      "Hyperopt - INFO - 0.819304152637486\n",
      "Hyperopt - INFO - 0.8181818181818182\n",
      "Hyperopt - INFO - 0.8181818181818182\n",
      "Hyperopt - INFO - 0.8170594837261503\n",
      "Hyperopt - INFO - 0.8170594837261503\n",
      "Hyperopt - INFO - 0.8170594837261503\n",
      "Hyperopt - INFO - 0.8103254769921436\n",
      "Hyperopt - INFO - 0.808080808080808\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8002244668911335\n",
      "Hyperopt - INFO - 0.7991021324354658\n",
      "Hyperopt - INFO - 0.7991021324354657\n",
      "Hyperopt - INFO - 0.7991021324354657\n",
      "Hyperopt - INFO - 0.7991021324354657\n",
      "Hyperopt - INFO - 0.797979797979798\n",
      "Hyperopt - INFO - 0.7957351290684623\n",
      "Hyperopt - INFO - 0.7957351290684623\n",
      "Hyperopt - INFO - 0.7946127946127947\n",
      "Hyperopt - INFO - 0.7946127946127947\n",
      "Hyperopt - INFO - 0.7946127946127945\n",
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7923681257014591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt - INFO - 0.7901234567901234\n",
      "Hyperopt - INFO - 0.7901234567901234\n",
      "Hyperopt - INFO - 0.7890011223344557\n",
      "Hyperopt - INFO - 0.7890011223344556\n",
      "Hyperopt - INFO - 0.7890011223344556\n",
      "Hyperopt - INFO - 0.7878787878787877\n",
      "Hyperopt - INFO - 0.7867564534231201\n",
      "Hyperopt - INFO - 0.7789001122334455\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004069 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004954 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.290685\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006655 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004256 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004565 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005019 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.199776\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004047 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004807 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.182941\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003645 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004090 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004175 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004945 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004830 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003937 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005428 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003897 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004371 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006399 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004266 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004596 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004014 seconds\n",
      "hyperopt.tpe - INFO - TPE using 20/20 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004562 seconds\n",
      "hyperopt.tpe - INFO - TPE using 21/21 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004307 seconds\n",
      "hyperopt.tpe - INFO - TPE using 22/22 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003881 seconds\n",
      "hyperopt.tpe - INFO - TPE using 23/23 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004036 seconds\n",
      "hyperopt.tpe - INFO - TPE using 24/24 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003996 seconds\n",
      "hyperopt.tpe - INFO - TPE using 25/25 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004070 seconds\n",
      "hyperopt.tpe - INFO - TPE using 26/26 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003881 seconds\n",
      "hyperopt.tpe - INFO - TPE using 27/27 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004099 seconds\n",
      "hyperopt.tpe - INFO - TPE using 28/28 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004117 seconds\n",
      "hyperopt.tpe - INFO - TPE using 29/29 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004349 seconds\n",
      "hyperopt.tpe - INFO - TPE using 30/30 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004192 seconds\n",
      "hyperopt.tpe - INFO - TPE using 31/31 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003735 seconds\n",
      "hyperopt.tpe - INFO - TPE using 32/32 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004654 seconds\n",
      "hyperopt.tpe - INFO - TPE using 33/33 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004165 seconds\n",
      "hyperopt.tpe - INFO - TPE using 34/34 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005802 seconds\n",
      "hyperopt.tpe - INFO - TPE using 35/35 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003912 seconds\n",
      "hyperopt.tpe - INFO - TPE using 36/36 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004298 seconds\n",
      "hyperopt.tpe - INFO - TPE using 37/37 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004918 seconds\n",
      "hyperopt.tpe - INFO - TPE using 38/38 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004620 seconds\n",
      "hyperopt.tpe - INFO - TPE using 39/39 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004717 seconds\n",
      "hyperopt.tpe - INFO - TPE using 40/40 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006233 seconds\n",
      "hyperopt.tpe - INFO - TPE using 41/41 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004055 seconds\n",
      "hyperopt.tpe - INFO - TPE using 42/42 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004317 seconds\n",
      "hyperopt.tpe - INFO - TPE using 43/43 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004950 seconds\n",
      "hyperopt.tpe - INFO - TPE using 44/44 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003995 seconds\n",
      "hyperopt.tpe - INFO - TPE using 45/45 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004726 seconds\n",
      "hyperopt.tpe - INFO - TPE using 46/46 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.003929 seconds\n",
      "hyperopt.tpe - INFO - TPE using 47/47 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004319 seconds\n",
      "hyperopt.tpe - INFO - TPE using 48/48 trials with best loss 0.181818\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.004048 seconds\n",
      "hyperopt.tpe - INFO - TPE using 49/49 trials with best loss 0.181818\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.8181818181818182\n",
      "Hyperopt - INFO - 0.8181818181818182\n",
      "Hyperopt - INFO - 0.8181818181818182\n",
      "Hyperopt - INFO - 0.8170594837261503\n",
      "Hyperopt - INFO - 0.8170594837261503\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8114478114478114\n",
      "Hyperopt - INFO - 0.8114478114478114\n",
      "Hyperopt - INFO - 0.8114478114478114\n",
      "Hyperopt - INFO - 0.8103254769921436\n",
      "Hyperopt - INFO - 0.8103254769921436\n",
      "Hyperopt - INFO - 0.8103254769921436\n",
      "Hyperopt - INFO - 0.8092031425364757\n",
      "Hyperopt - INFO - 0.8080808080808081\n",
      "Hyperopt - INFO - 0.808080808080808\n",
      "Hyperopt - INFO - 0.8058361391694725\n",
      "Hyperopt - INFO - 0.8035914702581369\n",
      "Hyperopt - INFO - 0.8035914702581369\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8002244668911335\n",
      "Hyperopt - INFO - 0.8002244668911335\n",
      "Hyperopt - INFO - 0.7991021324354658\n",
      "Hyperopt - INFO - 0.7979797979797979\n",
      "Hyperopt - INFO - 0.7968574635241302\n",
      "Hyperopt - INFO - 0.7957351290684623\n",
      "Hyperopt - INFO - 0.7946127946127947\n",
      "Hyperopt - INFO - 0.7946127946127947\n",
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7923681257014591\n",
      "Hyperopt - INFO - 0.7878787878787877\n",
      "Hyperopt - INFO - 0.7867564534231201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt - INFO - 0.7867564534231201\n",
      "Hyperopt - INFO - 0.7845117845117846\n",
      "Hyperopt - INFO - 0.7845117845117845\n",
      "Hyperopt - INFO - 0.7789001122334455\n",
      "Hyperopt - INFO - 0.7093153759820426\n",
      "Hyperopt - INFO - 0.7093153759820426\n",
      "Hyperopt - INFO - 0.7093153759820426\n",
      "Hyperopt - INFO - 0.7070707070707071\n",
      "Hyperopt - INFO - 0.7070707070707071\n",
      "Hyperopt - INFO - 0.7070707070707071\n",
      "Hyperopt - INFO - 0.7070707070707071\n",
      "Hyperopt - INFO - 0.7070707070707071\n",
      "Hyperopt - INFO - Running hyperparameter optimization for <class 'xgboost.sklearn.XGBClassifier'>\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005085 seconds\n",
      "hyperopt.tpe - INFO - TPE using 0 trials\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006369 seconds\n",
      "hyperopt.tpe - INFO - TPE using 1/1 trials with best loss 0.223345\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007089 seconds\n",
      "hyperopt.tpe - INFO - TPE using 2/2 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005959 seconds\n",
      "hyperopt.tpe - INFO - TPE using 3/3 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005948 seconds\n",
      "hyperopt.tpe - INFO - TPE using 4/4 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006277 seconds\n",
      "hyperopt.tpe - INFO - TPE using 5/5 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006279 seconds\n",
      "hyperopt.tpe - INFO - TPE using 6/6 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006231 seconds\n",
      "hyperopt.tpe - INFO - TPE using 7/7 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005936 seconds\n",
      "hyperopt.tpe - INFO - TPE using 8/8 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006596 seconds\n",
      "hyperopt.tpe - INFO - TPE using 9/9 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005543 seconds\n",
      "hyperopt.tpe - INFO - TPE using 10/10 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007140 seconds\n",
      "hyperopt.tpe - INFO - TPE using 11/11 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005999 seconds\n",
      "hyperopt.tpe - INFO - TPE using 12/12 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005736 seconds\n",
      "hyperopt.tpe - INFO - TPE using 13/13 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005981 seconds\n",
      "hyperopt.tpe - INFO - TPE using 14/14 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005827 seconds\n",
      "hyperopt.tpe - INFO - TPE using 15/15 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005930 seconds\n",
      "hyperopt.tpe - INFO - TPE using 16/16 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005755 seconds\n",
      "hyperopt.tpe - INFO - TPE using 17/17 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006641 seconds\n",
      "hyperopt.tpe - INFO - TPE using 18/18 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006300 seconds\n",
      "hyperopt.tpe - INFO - TPE using 19/19 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006302 seconds\n",
      "hyperopt.tpe - INFO - TPE using 20/20 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008576 seconds\n",
      "hyperopt.tpe - INFO - TPE using 21/21 trials with best loss 0.175084\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006071 seconds\n",
      "hyperopt.tpe - INFO - TPE using 22/22 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005910 seconds\n",
      "hyperopt.tpe - INFO - TPE using 23/23 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007776 seconds\n",
      "hyperopt.tpe - INFO - TPE using 24/24 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.008932 seconds\n",
      "hyperopt.tpe - INFO - TPE using 25/25 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006435 seconds\n",
      "hyperopt.tpe - INFO - TPE using 26/26 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006357 seconds\n",
      "hyperopt.tpe - INFO - TPE using 27/27 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007537 seconds\n",
      "hyperopt.tpe - INFO - TPE using 28/28 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005887 seconds\n",
      "hyperopt.tpe - INFO - TPE using 29/29 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006235 seconds\n",
      "hyperopt.tpe - INFO - TPE using 30/30 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007248 seconds\n",
      "hyperopt.tpe - INFO - TPE using 31/31 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006014 seconds\n",
      "hyperopt.tpe - INFO - TPE using 32/32 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005942 seconds\n",
      "hyperopt.tpe - INFO - TPE using 33/33 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005807 seconds\n",
      "hyperopt.tpe - INFO - TPE using 34/34 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005627 seconds\n",
      "hyperopt.tpe - INFO - TPE using 35/35 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006266 seconds\n",
      "hyperopt.tpe - INFO - TPE using 36/36 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006160 seconds\n",
      "hyperopt.tpe - INFO - TPE using 37/37 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006299 seconds\n",
      "hyperopt.tpe - INFO - TPE using 38/38 trials with best loss 0.172840\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005803 seconds\n",
      "hyperopt.tpe - INFO - TPE using 39/39 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007015 seconds\n",
      "hyperopt.tpe - INFO - TPE using 40/40 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006445 seconds\n",
      "hyperopt.tpe - INFO - TPE using 41/41 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005807 seconds\n",
      "hyperopt.tpe - INFO - TPE using 42/42 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006432 seconds\n",
      "hyperopt.tpe - INFO - TPE using 43/43 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005957 seconds\n",
      "hyperopt.tpe - INFO - TPE using 44/44 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005903 seconds\n",
      "hyperopt.tpe - INFO - TPE using 45/45 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005778 seconds\n",
      "hyperopt.tpe - INFO - TPE using 46/46 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.006256 seconds\n",
      "hyperopt.tpe - INFO - TPE using 47/47 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.007013 seconds\n",
      "hyperopt.tpe - INFO - TPE using 48/48 trials with best loss 0.171717\n",
      "hyperopt.tpe - INFO - tpe_transform took 0.005943 seconds\n",
      "hyperopt.tpe - INFO - TPE using 49/49 trials with best loss 0.171717\n",
      "Hyperopt - INFO - Reversing best score bask to original form as reverse_score=True\n",
      "Hyperopt - INFO - 0.8282828282828283\n",
      "Hyperopt - INFO - 0.8271604938271605\n",
      "Hyperopt - INFO - 0.8271604938271605\n",
      "Hyperopt - INFO - 0.8260381593714926\n",
      "Hyperopt - INFO - 0.8249158249158249\n",
      "Hyperopt - INFO - 0.8249158249158249\n",
      "Hyperopt - INFO - 0.819304152637486\n",
      "Hyperopt - INFO - 0.8170594837261506\n",
      "Hyperopt - INFO - 0.8170594837261503\n",
      "Hyperopt - INFO - 0.8159371492704827\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8136924803591471\n",
      "Hyperopt - INFO - 0.8125701459034792\n",
      "Hyperopt - INFO - 0.8125701459034792\n",
      "Hyperopt - INFO - 0.8103254769921437\n",
      "Hyperopt - INFO - 0.809203142536476\n",
      "Hyperopt - INFO - 0.809203142536476\n",
      "Hyperopt - INFO - 0.809203142536476\n",
      "Hyperopt - INFO - 0.8092031425364757\n",
      "Hyperopt - INFO - 0.8058361391694725\n",
      "Hyperopt - INFO - 0.8058361391694725\n",
      "Hyperopt - INFO - 0.8047138047138046\n",
      "Hyperopt - INFO - 0.8035914702581369\n",
      "Hyperopt - INFO - 0.8035914702581369\n",
      "Hyperopt - INFO - 0.8024691358024691\n",
      "Hyperopt - INFO - 0.8013468013468014\n",
      "Hyperopt - INFO - 0.8013468013468014\n",
      "Hyperopt - INFO - 0.8002244668911335\n",
      "Hyperopt - INFO - 0.7991021324354657\n",
      "Hyperopt - INFO - 0.7991021324354657\n",
      "Hyperopt - INFO - 0.7979797979797979\n",
      "Hyperopt - INFO - 0.7957351290684623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7934904601571269\n",
      "Hyperopt - INFO - 0.7912457912457912\n",
      "Hyperopt - INFO - 0.7901234567901234\n",
      "Hyperopt - INFO - 0.7901234567901234\n",
      "Hyperopt - INFO - 0.7890011223344556\n",
      "Hyperopt - INFO - 0.787878787878788\n",
      "Hyperopt - INFO - 0.77665544332211\n",
      "Hyperopt - INFO - 0.7755331088664422\n",
      "Hyperopt - INFO - 0.7755331088664422\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      "Hyperopt - INFO - 0.6161616161616161\n",
      " 67%|██████▋   | 2/3 [01:26<00:43, 43.36s/it]LocalExecutor - INFO - Running step 'ChooseBest'\n",
      "ChooseBest - INFO - Final model scores:\n",
      "ChooseBest - INFO - RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=0.11839601117622323,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=13, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) - 0.830527497194164\n",
      "ChooseBest - INFO - XGBClassifier(base_score=0.5, colsample_bylevel=0.5274114609535807,\n",
      "       colsample_bytree=0.7442829074010315, gamma=2.5822029701759326,\n",
      "       learning_rate=0.0001290885134641065, max_delta_step=0, max_depth=7,\n",
      "       min_child_weight=3, missing=None, n_estimators=1200, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0.4217424311777345,\n",
      "       reg_lambda=1.338106856870948, scale_pos_weight=1, seed=4,\n",
      "       silent=True, subsample=0.9632875017009653) - 0.8282828282828283\n",
      "ChooseBest - INFO - KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='uniform') - 0.8181818181818182\n",
      "100%|██████████| 3/3 [01:26<00:00, 28.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=3, max_features=0.11839601117622323,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=13, n_jobs=1, oob_score=False, random_state=4,\n",
      "            verbose=False, warm_start=False) 0.830527497194164\n",
      "(891, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "context, pipeline_data = LocalExecutor(pipeline_data.dataset, epochs=1) << \\\n",
    "    (Pipeline()\n",
    "     >> PipelineStep('model space', ModelSpace(model_list), initializer=True)\n",
    "     >> Hyperopt(CV(scoring=make_scorer(accuracy_score)), max_evals=50)\n",
    "     >> ChooseBest(1))\n",
    "\n",
    "for result in pipeline_data.return_val:\n",
    "    print(result.model, result.score)\n",
    "print(pipeline_data.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got a nice improvement. That's enough to get into the top 1% in the Kaggle Titatic demo competition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
